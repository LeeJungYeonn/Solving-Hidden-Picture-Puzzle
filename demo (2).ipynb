{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Demo\n",
        "@ Team 1"
      ],
      "metadata": {
        "id": "4uSNLNpqCTGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Hidden-Picture-Puzzle/Solving-Hidden-Picture-Puzzle.git\n",
        "%cd Solving-Hidden-Picture-Puzzle\n",
        "!ls"
      ],
      "metadata": {
        "id": "cshjQpZUPAIC",
        "outputId": "0ec99cf6-5ba1-468a-dc6e-9c3323553388",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Solving-Hidden-Picture-Puzzle'...\n",
            "remote: Enumerating objects: 494, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 494 (delta 35), reused 4 (delta 4), pack-reused 449 (from 1)\u001b[K\n",
            "Receiving objects: 100% (494/494), 47.18 MiB | 20.52 MiB/s, done.\n",
            "Resolving deltas: 100% (97/97), done.\n",
            "/content/Solving-Hidden-Picture-Puzzle\n",
            "dataset  demo.ipynb  README.md\trequirements.txt  result  test\ttest_result\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "M_jYBlSJPFq2",
        "outputId": "859c814a-8d0a-4d66-e735-f7ef3f36f9cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (4.12.0.88)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (1.16.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 4)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 4)) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting"
      ],
      "metadata": {
        "id": "yujvurs5Rmem"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fE4VKFR86CRU"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from scipy.ndimage import distance_transform_edt\n",
        "from joblib import Parallel, delayed\n",
        "import multiprocessing\n",
        "import pandas as pd\n",
        "import cv2.ximgproc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErrqA27Ms5OF"
      },
      "source": [
        "## Matching Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grayscale Chamfer Matching"
      ],
      "metadata": {
        "id": "tIz1xyHNtPgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GrayscaleChamferMatcher:\n",
        "    def __init__(self, scene_path: str, truncation_dist=40.0):\n",
        "        self.scene = cv2.imread(scene_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if self.scene is None:\n",
        "            raise ValueError(f\"Failed to load scene: {scene_path}\")\n",
        "\n",
        "        self.truncation_dist = truncation_dist\n",
        "        self.num_ori_bins = 8\n",
        "        self.ori_bin_angle = 180.0 / self.num_ori_bins\n",
        "\n",
        "        self.edges_fine, self.orient_map_fine = self._extract_edges_and_orientation_adaptive(self.scene)\n",
        "        self.dir_dist_maps_fine = self._build_truncated_directional_distance_maps(\n",
        "            self.edges_fine, self.orient_map_fine\n",
        "        )\n",
        "        self.integral_edges_fine = cv2.integral(self.edges_fine.astype(np.float32) / 255.0)\n",
        "\n",
        "        self.coarse_scale = 0.5\n",
        "        scene_small = cv2.resize(self.scene, None, fx=self.coarse_scale, fy=self.coarse_scale)\n",
        "\n",
        "        self.edges_coarse, self.orient_map_coarse = self._extract_edges_and_orientation_adaptive(scene_small)\n",
        "        self.dir_dist_maps_coarse = self._build_truncated_directional_distance_maps(\n",
        "            self.edges_coarse, self.orient_map_coarse\n",
        "        )\n",
        "        self.integral_edges_coarse = cv2.integral(self.edges_coarse.astype(np.float32) / 255.0)\n",
        "\n",
        "    def _extract_edges_and_orientation_adaptive(self, img):\n",
        "        \"\"\"\n",
        "        Sceneìš©: Canny(50,150) + Morph + Skeleton\n",
        "        \"\"\"\n",
        "        blurred = cv2.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)\n",
        "\n",
        "        edges = cv2.Canny(blurred, 50, 150, L2gradient=True)\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
        "        edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
        "\n",
        "        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(edges, connectivity=8)\n",
        "        clean_edges = np.zeros_like(edges)\n",
        "        for i in range(1, num_labels):\n",
        "            if stats[i, cv2.CC_STAT_AREA] >= 10:\n",
        "                clean_edges[labels == i] = 255\n",
        "\n",
        "        skeleton = np.zeros(clean_edges.shape, np.uint8)\n",
        "        img_temp = clean_edges.copy()\n",
        "        element = cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3))\n",
        "\n",
        "        while True:\n",
        "            eroded = cv2.erode(img_temp, element)\n",
        "            temp = cv2.dilate(eroded, element)\n",
        "            temp = cv2.subtract(img_temp, temp)\n",
        "            skeleton = cv2.bitwise_or(skeleton, temp)\n",
        "            img_temp = eroded.copy()\n",
        "            if cv2.countNonZero(img_temp) == 0:\n",
        "                break\n",
        "\n",
        "        edges = skeleton\n",
        "\n",
        "        gx = cv2.Sobel(img, cv2.CV_32F, 1, 0, ksize=3)\n",
        "        gy = cv2.Sobel(img, cv2.CV_32F, 0, 1, ksize=3)\n",
        "        grad_angle = np.rad2deg(np.arctan2(gy, gx))\n",
        "        grad_angle[grad_angle < 0] += 180.0\n",
        "\n",
        "        orient_map = np.full(grad_angle.shape, -1, dtype=np.float32)\n",
        "        orient_map[edges > 0] = grad_angle[edges > 0]\n",
        "\n",
        "        return edges, orient_map\n",
        "\n",
        "    def _extract_template_edges_and_orientation(self, template_image):\n",
        "        \"\"\"\n",
        "        Templateìš©: Canny(30,100) + Skeleton (1px)\n",
        "        \"\"\"\n",
        "\n",
        "        if len(template_image.shape) == 3:\n",
        "            gray_img = cv2.cvtColor(template_image, cv2.COLOR_BGR2GRAY)\n",
        "        else:\n",
        "            gray_img = template_image\n",
        "\n",
        "        blurred = cv2.bilateralFilter(gray_img, d=5, sigmaColor=30, sigmaSpace=30)\n",
        "        edges = cv2.Canny(blurred, 30, 100, L2gradient=True)\n",
        "\n",
        "        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(edges, connectivity=8)\n",
        "        clean_edges = np.zeros_like(edges)\n",
        "        for i in range(1, num_labels):\n",
        "            if stats[i, cv2.CC_STAT_AREA] >= 10:\n",
        "                clean_edges[labels == i] = 255\n",
        "\n",
        "        skeleton = np.zeros(clean_edges.shape, np.uint8)\n",
        "        img_temp = clean_edges.copy()\n",
        "        element = cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3))\n",
        "\n",
        "        while True:\n",
        "            eroded = cv2.erode(img_temp, element)\n",
        "            temp = cv2.dilate(eroded, element)\n",
        "            temp = cv2.subtract(img_temp, temp)\n",
        "            skeleton = cv2.bitwise_or(skeleton, temp)\n",
        "            img_temp = eroded.copy()\n",
        "            if cv2.countNonZero(img_temp) == 0:\n",
        "                break\n",
        "\n",
        "        edges = skeleton\n",
        "\n",
        "        gx = cv2.Sobel(gray_img, cv2.CV_32F, 1, 0, ksize=3)\n",
        "        gy = cv2.Sobel(gray_img, cv2.CV_32F, 0, 1, ksize=3)\n",
        "        grad_angle = np.rad2deg(np.arctan2(gy, gx))\n",
        "        grad_angle[grad_angle < 0] += 180.0\n",
        "\n",
        "        orient_map = np.full(grad_angle.shape, -1, dtype=np.float32)\n",
        "        orient_map[edges > 0] = grad_angle[edges > 0]\n",
        "\n",
        "        return edges, orient_map\n",
        "\n",
        "    def _build_truncated_directional_distance_maps(self, edges, orient_map):\n",
        "        h, w = edges.shape\n",
        "        dist_maps = []\n",
        "        for b in range(self.num_ori_bins):\n",
        "            ang_min = b * self.ori_bin_angle\n",
        "            ang_max = (b + 1) * self.ori_bin_angle\n",
        "\n",
        "            mask = np.zeros((h, w), dtype=np.uint8)\n",
        "            bin_mask = (orient_map >= ang_min) & (orient_map < ang_max)\n",
        "            mask[bin_mask] = 1\n",
        "\n",
        "            inv_mask = 1 - mask\n",
        "            dist = distance_transform_edt(inv_mask)\n",
        "\n",
        "            # (ìµœì í™”) Truncation ë¯¸ë¦¬ ì ìš©\n",
        "            dist = np.minimum(dist, self.truncation_dist).astype(np.float32)\n",
        "            dist_maps.append(dist)\n",
        "\n",
        "        return dist_maps\n",
        "\n",
        "    def _rotate_template(self, image, angle):\n",
        "        if angle == 0: return image.copy()\n",
        "        (h, w) = image.shape[:2]\n",
        "        (cX, cY) = (w // 2, h // 2)\n",
        "        M = cv2.getRotationMatrix2D((cX, cY), angle, 1.0)\n",
        "        cos, sin = np.abs(M[0, 0]), np.abs(M[0, 1])\n",
        "        nW = int((h * sin) + (w * cos))\n",
        "        nH = int((h * cos) + (w * sin))\n",
        "        M[0, 2] += (nW / 2) - cX\n",
        "        M[1, 2] += (nH / 2) - cY\n",
        "        return cv2.warpAffine(image, M, (nW, nH), flags=cv2.INTER_NEAREST, borderValue=0)\n",
        "\n",
        "    def _get_template_masks_by_bin(self, template_gray):\n",
        "        edges, grad_angle = self._extract_template_edges_and_orientation(template_gray)\n",
        "\n",
        "        valid = edges > 0\n",
        "        bins = (grad_angle[valid] // self.ori_bin_angle).astype(np.int32)\n",
        "        bins = np.clip(bins, 0, self.num_ori_bins - 1)\n",
        "\n",
        "        masks = []\n",
        "        for b in range(self.num_ori_bins):\n",
        "            mask = np.zeros_like(edges, dtype=np.float32)\n",
        "            # bin_mapì„ ë‹¤ì‹œ ë§Œë“œëŠ” ëŒ€ì‹  ë°”ë¡œ ë§ˆìŠ¤í‚¹\n",
        "            # í˜„ì¬ binì¸ í”½ì…€ë“¤ë§Œ 1.0\n",
        "            mask_indices = (bins == b)\n",
        "            # validí•œ í”½ì…€ ì¤‘ binì´ bì¸ ê²ƒë“¤ì˜ ì¢Œí‘œ\n",
        "            y_idxs, x_idxs = np.where(valid)\n",
        "            y_b = y_idxs[mask_indices]\n",
        "            x_b = x_idxs[mask_indices]\n",
        "            mask[y_b, x_b] = 1.0\n",
        "            masks.append(mask)\n",
        "\n",
        "        return masks, edges\n",
        "\n",
        "    def _compute_score_map_fast(self, dist_maps, template_masks):\n",
        "        total_cost_map = None\n",
        "\n",
        "        for b in range(self.num_ori_bins):\n",
        "            t_mask = template_masks[b]\n",
        "            if np.sum(t_mask) == 0:\n",
        "                continue\n",
        "\n",
        "            # TM_CCORR: í…œí”Œë¦¿(1)ê³¼ ê²¹ì¹˜ëŠ” ì´ë¯¸ì§€ í”½ì…€(ê±°ë¦¬ê°’)ì„ ë‹¤ ë”í•¨\n",
        "            # ìˆ˜ì‹: sum( dist_map(x+i, y+j) * template(i, j) )\n",
        "            cost = cv2.matchTemplate(dist_maps[b], t_mask, cv2.TM_CCORR)\n",
        "\n",
        "            if total_cost_map is None:\n",
        "                total_cost_map = cost\n",
        "            else:\n",
        "                total_cost_map += cost\n",
        "\n",
        "        return total_cost_map\n",
        "\n",
        "    def _get_edge_density_fast(self, integral_img, x, y, w, h):\n",
        "        \"\"\"Integral Imageë¥¼ ì´ìš©í•œ O(1) Edge Density ê³„ì‚°\"\"\"\n",
        "        # Integral imageëŠ” ì›ë³¸ë³´ë‹¤ í¬ê¸°ê°€ 1ì”© í¼\n",
        "        # Sum = I[y2, x2] - I[y1, x2] - I[y2, x1] + I[y1, x1]\n",
        "        y2 = min(y + h, integral_img.shape[0] - 1)\n",
        "        x2 = min(x + w, integral_img.shape[1] - 1)\n",
        "        y1 = max(y, 0)\n",
        "        x1 = max(x, 0)\n",
        "\n",
        "        count = (integral_img[y2, x2]\n",
        "                 - integral_img[y1, x2]\n",
        "                 - integral_img[y2, x1]\n",
        "                 + integral_img[y1, x1])\n",
        "        return count\n",
        "\n",
        "    def _process_single_scale_and_angle(self, scale, angle, template_gray_orig, orig_w, orig_h):\n",
        "        # --- 1. Coarse ë‹¨ê³„ (ê³ ì† í•„í„°ë§) ---\n",
        "        c_w = int(orig_w * scale * self.coarse_scale)\n",
        "        c_h = int(orig_h * scale * self.coarse_scale)\n",
        "\n",
        "        # Scene(Coarse) í¬ê¸°ë³´ë‹¤ í…œí”Œë¦¿ì´ í¬ë©´ ì¦‰ì‹œ ì¤‘ë‹¨\n",
        "        scene_h_coarse, scene_w_coarse = self.dir_dist_maps_coarse[0].shape\n",
        "\n",
        "        if c_w >= scene_w_coarse or c_h >= scene_h_coarse: return None\n",
        "        if c_w < 5 or c_h < 5: return None\n",
        "\n",
        "        t_coarse_resized = cv2.resize(template_gray_orig, (c_w, c_h))\n",
        "        t_coarse_rot = self._rotate_template(t_coarse_resized, angle)\n",
        "\n",
        "        # íšŒì „ í›„ í¬ê¸°ê°€ Sceneë³´ë‹¤ í°ì§€ í•œ ë²ˆ ë” ì²´í¬\n",
        "        tc_h, tc_w = t_coarse_rot.shape\n",
        "        if tc_w > scene_w_coarse or tc_h > scene_h_coarse: return None\n",
        "\n",
        "        t_coarse_masks, t_coarse_edges = self._get_template_masks_by_bin(t_coarse_rot)\n",
        "\n",
        "        edge_pixel_count = np.sum(t_coarse_edges > 0)\n",
        "        if edge_pixel_count == 0: return None\n",
        "\n",
        "        # (ìµœì í™”) ì „ì²´ ë§µì— ëŒ€í•´ í•œ ë²ˆì— ì ìˆ˜ ê³„ì‚°\n",
        "        try:\n",
        "            score_map_coarse = self._compute_score_map_fast(self.dir_dist_maps_coarse, t_coarse_masks)\n",
        "        except cv2.error:\n",
        "            return None\n",
        "\n",
        "        if score_map_coarse is None: return None\n",
        "\n",
        "        score_map_coarse /= edge_pixel_count\n",
        "\n",
        "        # ìµœì†Œ ë¹„ìš© ìœ„ì¹˜ ì°¾ê¸°\n",
        "        min_val, _, min_loc, _ = cv2.minMaxLoc(score_map_coarse)\n",
        "\n",
        "        # Coarse Threshold (truncationì˜ ì ˆë°˜ë³´ë‹¤ í¬ë©´ ë²„ë¦¼)\n",
        "        if min_val > self.truncation_dist * 0.6:\n",
        "            return None\n",
        "\n",
        "        best_c_loc = min_loc  # (x, y)\n",
        "\n",
        "        # --- 2. Fine ë‹¨ê³„ (ì •ë°€ ê²€ì‚¬) ---\n",
        "        # ì¢Œí‘œ ë³µì›\n",
        "        orig_cx = int(best_c_loc[0] / self.coarse_scale)\n",
        "        orig_cy = int(best_c_loc[1] / self.coarse_scale)\n",
        "\n",
        "        f_w = int(orig_w * scale)\n",
        "        f_h = int(orig_h * scale)\n",
        "\n",
        "        scene_h_fine, scene_w_fine = self.dir_dist_maps_fine[0].shape\n",
        "        if f_w >= scene_w_fine or f_h >= scene_h_fine: return None\n",
        "        if f_w < 5 or f_h < 5: return None\n",
        "\n",
        "        t_fine_resized = cv2.resize(template_gray_orig, (f_w, f_h))\n",
        "        t_fine_rot = self._rotate_template(t_fine_resized, angle)\n",
        "\n",
        "        tf_h, tf_w = t_fine_rot.shape\n",
        "        if tf_w > scene_w_fine or tf_h > scene_h_fine: return None\n",
        "\n",
        "        t_fine_masks, t_fine_edges = self._get_template_masks_by_bin(t_fine_rot)\n",
        "\n",
        "        fine_edge_count = np.sum(t_fine_edges > 0)\n",
        "        if fine_edge_count == 0: return None\n",
        "\n",
        "        # ROI ì„¤ì •\n",
        "        margin = 20\n",
        "        start_x = max(0, orig_cx - margin)\n",
        "        start_y = max(0, orig_cy - margin)\n",
        "        end_x = min(self.dir_dist_maps_fine[0].shape[1], orig_cx + f_w + margin)\n",
        "        end_y = min(self.dir_dist_maps_fine[0].shape[0], orig_cy + f_h + margin)\n",
        "\n",
        "        roi_w = end_x - start_x\n",
        "        roi_h = end_y - start_y\n",
        "\n",
        "        # ROIê°€ í…œí”Œë¦¿ë³´ë‹¤ ì‘ìœ¼ë©´ ë§¤ì¹­ ë¶ˆê°€\n",
        "        if roi_w < tf_w or roi_h < tf_h: return None\n",
        "\n",
        "        # ROI í¬ë¡­ëœ Distance Maps\n",
        "        roi_dist_maps = [d[start_y:end_y, start_x:end_x] for d in self.dir_dist_maps_fine]\n",
        "\n",
        "        # ROI ë‚´ì—ì„œ ë§¤ì¹­\n",
        "        try:\n",
        "            score_map_fine = self._compute_score_map_fast(roi_dist_maps, t_fine_masks)\n",
        "        except cv2.error:\n",
        "            return None\n",
        "\n",
        "        if score_map_fine is None: return None\n",
        "\n",
        "        score_map_fine /= fine_edge_count\n",
        "\n",
        "        # ROI ë‚´ ìµœì†Œê°’\n",
        "        min_dist, _, min_loc_roi, _ = cv2.minMaxLoc(score_map_fine)\n",
        "\n",
        "        # ì „ì²´ ì¢Œí‘œê³„ë¡œ ë³€í™˜\n",
        "        final_x = start_x + min_loc_roi[0]\n",
        "        final_y = start_y + min_loc_roi[1]\n",
        "\n",
        "        # Edge Density Penalty (O(1) ì¡°íšŒ)\n",
        "        scene_edge_cnt = self._get_edge_density_fast(\n",
        "            self.integral_edges_fine, final_x, final_y, tf_w, tf_h\n",
        "        )\n",
        "        ratio = scene_edge_cnt / fine_edge_count\n",
        "        penalty = 1.0\n",
        "        if ratio > 6.0: # max_ratio\n",
        "            penalty = ratio / 6.0\n",
        "\n",
        "        final_dist = min_dist * penalty\n",
        "\n",
        "        # Score ë³€í™˜ (0~1)\n",
        "        final_score = max(0, 1.0 - (final_dist / self.truncation_dist))\n",
        "\n",
        "        return {\n",
        "            'scale': round(scale, 2),\n",
        "            'angle': angle,\n",
        "            'score': round(final_score, 4),\n",
        "            'chamfer_distance': round(final_dist, 4),\n",
        "            'location': (final_x, final_y),\n",
        "            'template_size': (f_w, f_h)\n",
        "        }\n",
        "\n",
        "    def match(self, template_path, label, scale_range=(0.7, 1.3), scale_step=0.1, rotation_step=15, **kwargs):\n",
        "        # í…œí”Œë¦¿ ë¡œë“œ í™•ì¸\n",
        "        template_gray_orig = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if template_gray_orig is None:\n",
        "            print(f\"Error: Cannot read template {template_path}\")\n",
        "            return {'label': label, 'best_score': 0, 'top_results': []}\n",
        "\n",
        "        orig_h, orig_w = template_gray_orig.shape\n",
        "\n",
        "        scales = np.arange(scale_range[0], scale_range[1] + scale_step / 2, scale_step)\n",
        "        angles = np.arange(0, 360, rotation_step)\n",
        "\n",
        "        # ë³‘ë ¬ ì²˜ë¦¬\n",
        "        results = Parallel(n_jobs=-1)(\n",
        "            delayed(self._process_single_scale_and_angle)(scale, angle, template_gray_orig, orig_w, orig_h)\n",
        "            for scale in scales\n",
        "            for angle in angles\n",
        "        )\n",
        "\n",
        "        valid_results = [r for r in results if r is not None]\n",
        "        top_results = sorted(valid_results, key=lambda x: x['score'], reverse=True)[:3]\n",
        "\n",
        "        if not top_results:\n",
        "            return {'label': label, 'best_score': 0, 'best_scale': 1.0, 'best_angle': 0, 'best_location': (0,0), 'top_results': []}\n",
        "\n",
        "        best_res = top_results[0]\n",
        "        print(f\"   --> Best: Scale {best_res['scale']}x | Angle {best_res['angle']}Â° | Score {best_res['score']:.4f}\")\n",
        "\n",
        "        return {\n",
        "            'label': label,\n",
        "            'best_scale': best_res['scale'],\n",
        "            'best_angle': best_res['angle'],\n",
        "            'best_score': best_res['score'],\n",
        "            'best_location': best_res['location'],\n",
        "            'best_template_size': best_res['template_size'],\n",
        "            'top_results': top_results\n",
        "        }"
      ],
      "metadata": {
        "id": "upQSHxmooofe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HSV í•„í„°ë§ í—¬í¼ í•¨ìˆ˜"
      ],
      "metadata": {
        "id": "Ny1C65qahd6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_optimal_k(data, max_k=8, threshold=0.15):\n",
        "    n_samples = data.shape[0]\n",
        "    if n_samples < max_k: return max(1, n_samples)\n",
        "\n",
        "    prev_compactness = float('inf')\n",
        "    best_k = 1\n",
        "\n",
        "    for k in range(1, max_k + 1):\n",
        "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "        compactness, _, _ = cv2.kmeans(data, k, None, criteria, 3, cv2.KMEANS_RANDOM_CENTERS)\n",
        "\n",
        "        if k == 1:\n",
        "            prev_compactness = compactness\n",
        "            continue\n",
        "\n",
        "        improvement = (prev_compactness - compactness) / prev_compactness\n",
        "        if improvement < threshold:\n",
        "            best_k = k - 1\n",
        "            break\n",
        "        best_k = k\n",
        "        prev_compactness = compactness\n",
        "\n",
        "    return best_k\n",
        "\n",
        "def get_hsv_ranges(template_path,\n",
        "                   auto_k=True, k=5,\n",
        "                   margin_h=10, margin_s=30, margin_v=30,\n",
        "                   min_valid_pixels=50):\n",
        "\n",
        "    img_bgr = cv2.imread(template_path)\n",
        "    if img_bgr is None:\n",
        "        print(f\"ì˜¤ë¥˜: {template_path} íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return []\n",
        "\n",
        "    # --- 1. GrabCut: ë°°ê²½(í°ìƒ‰, ë°•ìŠ¤ ë“±)ì„ ë‚ ë¦¬ê³  ë¬¼ì²´ë§Œ ë‚¨ê¹€ ---\n",
        "    mask = np.zeros(img_bgr.shape[:2], np.uint8)\n",
        "    bgdModel = np.zeros((1, 65), np.float64)\n",
        "    fgdModel = np.zeros((1, 65), np.float64)\n",
        "\n",
        "    h, w = img_bgr.shape[:2]\n",
        "    rect = (1, 1, w-2, h-2)\n",
        "\n",
        "    # GrabCut ì‹¤í–‰ (ë°˜ë³µ 5íšŒ)\n",
        "    try:\n",
        "        cv2.grabCut(img_bgr, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
        "    except Exception as e:\n",
        "        print(f\"GrabCut ì‹¤íŒ¨: {e}\")\n",
        "        return []\n",
        "\n",
        "    # 0(ë°°ê²½), 2(ë°°ê²½ì¶”ì •) -> 0 / 1(ì „ê²½), 3(ì „ê²½ì¶”ì •) -> 1\n",
        "    mask_final = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
        "\n",
        "    # ë¬¼ì²´ í”½ì…€ ê°œìˆ˜ í™•ì¸\n",
        "    if np.count_nonzero(mask_final) < min_valid_pixels:\n",
        "        print(\"GrabCut ê²°ê³¼ ë¬¼ì²´ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "        return []\n",
        "\n",
        "    # --- 2. ë¬¼ì²´ ì˜ì—­ì˜ HSV í”½ì…€ë§Œ ì¶”ì¶œ ---\n",
        "    img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # ë§ˆìŠ¤í¬ê°€ 1ì¸ ë¶€ë¶„(ë¬¼ì²´)ì˜ í”½ì…€ë§Œ ê°€ì ¸ì˜´\n",
        "    valid_data = img_hsv[mask_final == 1].astype(np.float32)\n",
        "\n",
        "    s_median = np.median(valid_data[:, 1])\n",
        "    if s_median < 8:\n",
        "        print(\"Template grayscale -> skip HSV\")\n",
        "        return []\n",
        "\n",
        "    # --- 3. K-Means êµ°ì§‘í™” ë° ë²”ìœ„ ì‚°ì¶œ ---\n",
        "    final_k = k\n",
        "    if auto_k:\n",
        "        sample_data = valid_data\n",
        "        if len(valid_data) > 1000:\n",
        "            indices = np.random.choice(len(valid_data), 1000, replace=False)\n",
        "            sample_data = valid_data[indices]\n",
        "        final_k = find_optimal_k(sample_data, max_k=8)\n",
        "\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "    _, labels, centers = cv2.kmeans(valid_data, final_k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
        "\n",
        "    ranges = []\n",
        "\n",
        "    for i in range(final_k):\n",
        "        # í˜„ì¬ ê·¸ë£¹ì˜ í”½ì…€ë“¤\n",
        "        cluster_pixels = valid_data[labels.flatten() == i]\n",
        "\n",
        "        if len(cluster_pixels) < min_valid_pixels // final_k:\n",
        "            continue\n",
        "\n",
        "        h_vals, s_vals, v_vals = cluster_pixels[:, 0], cluster_pixels[:, 1], cluster_pixels[:, 2]\n",
        "\n",
        "        # S, V ë²”ìœ„ ê³„ì‚°\n",
        "        s_min = max(0, np.percentile(s_vals, 5) - margin_s)\n",
        "        s_max = min(255, np.percentile(s_vals, 95) + margin_s)\n",
        "        v_min = max(0, np.percentile(v_vals, 5) - margin_v)\n",
        "        v_max = min(255, np.percentile(v_vals, 95) + margin_v)\n",
        "\n",
        "        # Hue Wrap-around ì²˜ë¦¬ (ë¹¨ê°„ìƒ‰ 0/179 ê²½ê³„ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´)\n",
        "        h_shifted = (h_vals + 90) % 180\n",
        "        h_start_s, h_end_s = np.percentile(h_shifted, 5), np.percentile(h_shifted, 95)\n",
        "        h_start_s -= margin_h\n",
        "        h_end_s += margin_h\n",
        "\n",
        "        h_start = (h_start_s - 90) % 180\n",
        "        h_end = (h_end_s - 90) % 180\n",
        "\n",
        "        # ê²½ê³„ì„  ì¹¨ë²” ì²´í¬\n",
        "        if h_start_s < 0 or h_end_s > 179 or h_start > h_end:\n",
        "            # ë²”ìœ„ê°€ ëŠì–´ì§„ ê²½ìš° -> ë‘ ê°œë¡œ ë¶„í• \n",
        "            ranges.append(((int(h_start), int(s_min), int(v_min)), (179, int(s_max), int(v_max))))\n",
        "            ranges.append(((0, int(s_min), int(v_min)), (int(h_end), int(s_max), int(v_max))))\n",
        "        else:\n",
        "            # ì¼ë°˜ì ì¸ ê²½ìš° -> í•˜ë‚˜ë¡œ ì¶”ê°€\n",
        "            ranges.append(((int(h_start), int(s_min), int(v_min)), (int(h_end), int(s_max), int(v_max))))\n",
        "\n",
        "    return ranges\n",
        "\n",
        "def is_scene_grayscale(scene_bgr, s_thresh=12, gray_ratio=0.95):\n",
        "    \"\"\"\n",
        "    sceneì´ ëŒ€ë¶€ë¶„ ë¬´ì±„ìƒ‰ì´ë©´ True\n",
        "    - HSVì—ì„œ S(ì±„ë„)ê°€ ë§¤ìš° ë‚®ì€ í”½ì…€ ë¹„ìœ¨ì´ gray_ratio ì´ìƒì´ë©´ í‘ë°±/ë¬´ì±„ìƒ‰ìœ¼ë¡œ íŒë‹¨\n",
        "    \"\"\"\n",
        "    hsv = cv2.cvtColor(scene_bgr, cv2.COLOR_BGR2HSV)\n",
        "    s = hsv[:, :, 1]\n",
        "    ratio = np.mean(s < s_thresh)\n",
        "    return ratio >= gray_ratio\n",
        "\n",
        "def create_color_mask(scene_path, template_path):\n",
        "    scene_bgr = cv2.imread(scene_path)\n",
        "    if scene_bgr is None:\n",
        "        raise FileNotFoundError(f\"Scene ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {scene_path}\")\n",
        "\n",
        "    if is_scene_grayscale(scene_bgr):\n",
        "        return None\n",
        "\n",
        "    hsv_scene = cv2.cvtColor(scene_bgr, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    ranges = get_hsv_ranges(template_path, auto_k=True)\n",
        "\n",
        "    if not ranges:\n",
        "        return None\n",
        "\n",
        "    final_mask = np.zeros(hsv_scene.shape[:2], dtype=np.uint8)\n",
        "    for lower, upper in ranges:\n",
        "        mask = cv2.inRange(hsv_scene, np.array(lower, dtype=np.uint8), np.array(upper, dtype=np.uint8))\n",
        "        final_mask = cv2.bitwise_or(final_mask, mask)\n",
        "\n",
        "    return final_mask"
      ],
      "metadata": {
        "id": "65PQtA1GB_V4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VHrf79G6r3i"
      },
      "source": [
        "### Color GHT Matching"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ColorGHTMatcher:\n",
        "    def __init__(self, scene_path: str):\n",
        "        self.scene_bgr = cv2.imread(scene_path)\n",
        "        self.scene = cv2.cvtColor(self.scene_bgr, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # ë…¸ì´ì¦ˆ ì œê±°\n",
        "        self.scene = cv2.bilateralFilter(self.scene, 5, 50, 50)\n",
        "\n",
        "        # 1. Fine Scale (ì›ë³¸)\n",
        "        self.grad_fine, self.orient_fine, self.mask_fine = self._compute_gradients(self.scene)\n",
        "\n",
        "        # 2. Coarse Scale (1/2 ì¶•ì†Œ)\n",
        "        self.coarse_scale = 0.5\n",
        "        scene_small = cv2.resize(self.scene, None, fx=self.coarse_scale, fy=self.coarse_scale)\n",
        "        self.grad_coarse, self.orient_coarse, self.mask_coarse = self._compute_gradients(scene_small)\n",
        "\n",
        "    def _compute_gradients(self, img):\n",
        "        \"\"\"Sobel Gradient, Orientation, Edge Mask ê³„ì‚°\"\"\"\n",
        "        dx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\n",
        "        dy = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)\n",
        "\n",
        "        magnitude = cv2.magnitude(dx, dy)\n",
        "        orientation = np.degrees(np.arctan2(dy, dx)).astype(int) % 360\n",
        "\n",
        "        # ì—£ì§€ ë§ˆìŠ¤í¬ (ë„ˆë¬´ ì•½í•œ ì—£ì§€ëŠ” íˆ¬í‘œì— ì°¸ì—¬ ì•ˆ ì‹œí‚´)\n",
        "        mask = magnitude > 30\n",
        "        return magnitude, orientation, mask\n",
        "\n",
        "    def _build_r_table(self, template):\n",
        "        \"\"\"Templateì˜ ê¸°ë³¸ R-Table ìƒì„± (0ë„, 1.0ë°°)\"\"\"\n",
        "        dx = cv2.Sobel(template, cv2.CV_64F, 1, 0, ksize=3)\n",
        "        dy = cv2.Sobel(template, cv2.CV_64F, 0, 1, ksize=3)\n",
        "\n",
        "        magnitude = cv2.magnitude(dx, dy)\n",
        "        orientation = np.degrees(np.arctan2(dy, dx)).astype(int) % 360\n",
        "        edge_mask = magnitude > 40\n",
        "\n",
        "        h, w = template.shape\n",
        "        xc, yc = w // 2, h // 2\n",
        "\n",
        "        y_idxs, x_idxs = np.where(edge_mask)\n",
        "        mags = magnitude[edge_mask]\n",
        "        ors = orientation[edge_mask]\n",
        "\n",
        "        r_table = {}\n",
        "        for x, y, mag, angle in zip(x_idxs, y_idxs, mags, ors):\n",
        "            if angle not in r_table: r_table[angle] = []\n",
        "            # (dx, dy, mag) ì €ì¥\n",
        "            r_table[angle].append((xc - x, yc - y, mag))\n",
        "\n",
        "        return r_table, (w, h)\n",
        "\n",
        "    def _get_rotated_r_table(self, r_table, angle, scale):\n",
        "        \"\"\"\n",
        "        R-tableì„ ë¯¸ë¦¬ íšŒì „ ë° ìŠ¤ì¼€ì¼ë§í•˜ì—¬ ìƒˆë¡œìš´ í…Œì´ë¸” ìƒì„±\n",
        "        -> Inner Loopì—ì„œ sin/cos ì—°ì‚° ì œê±° -> ì†ë„ í–¥ìƒ\n",
        "        \"\"\"\n",
        "        theta_rad = np.radians(angle)\n",
        "        cos_t = np.cos(theta_rad)\n",
        "        sin_t = np.sin(theta_rad)\n",
        "\n",
        "        rotated_r_table = {}\n",
        "\n",
        "        for t_angle, vectors in r_table.items():\n",
        "            # í…œí”Œë¦¿ì´ íšŒì „í•˜ë©´ ì—£ì§€ ê°ë„ë„ íšŒì „í•¨\n",
        "            # Sceneì—ì„œ ì°¾ì„ ë•ŒëŠ” (ê¸°ì¡´ ê°ë„ + íšŒì „ ê°ë„)ë¥¼ í‚¤ë¡œ ì‚¬ìš©\n",
        "            scene_query_angle = int(t_angle + angle) % 360\n",
        "\n",
        "            new_vectors = []\n",
        "            for dx, dy, mag in vectors:\n",
        "                # 1. ë²¡í„° íšŒì „\n",
        "                rdx = dx * cos_t - dy * sin_t\n",
        "                rdy = dx * sin_t + dy * cos_t\n",
        "\n",
        "                # 2. ìŠ¤ì¼€ì¼ ì ìš©\n",
        "                final_dx = int(rdx * scale)\n",
        "                final_dy = int(rdy * scale)\n",
        "\n",
        "                new_vectors.append((final_dx, final_dy, mag))\n",
        "\n",
        "            if scene_query_angle not in rotated_r_table:\n",
        "                rotated_r_table[scene_query_angle] = []\n",
        "            rotated_r_table[scene_query_angle].extend(new_vectors)\n",
        "\n",
        "        return rotated_r_table\n",
        "\n",
        "    def _vote(self, rotated_r_table, scene_grad, scene_orient, scene_mask):\n",
        "        h, w = scene_grad.shape\n",
        "        accumulator = np.zeros((h, w), dtype=np.float32)\n",
        "\n",
        "        # Scene ì—£ì§€ í”½ì…€ ì¶”ì¶œ\n",
        "        y_idxs, x_idxs = np.where(scene_mask)\n",
        "        s_mags = scene_grad[scene_mask]\n",
        "        s_ors = scene_orient[scene_mask]\n",
        "\n",
        "        # íˆ¬í‘œ\n",
        "        for i, (sy, sx) in enumerate(zip(y_idxs, x_idxs)):\n",
        "            scene_angle = s_ors[i]\n",
        "\n",
        "            # ë¯¸ë¦¬ ë§Œë“¤ì–´ë‘” Rotated Table ì¡°íšŒ\n",
        "            if scene_angle in rotated_r_table:\n",
        "                for rdx, rdy, rmag in rotated_r_table[scene_angle]:\n",
        "                    # ì´ë¯¸ íšŒì „/ìŠ¤ì¼€ì¼ë§ ëœ ë²¡í„°ë¥¼ ë”í•˜ê¸°ë§Œ í•¨\n",
        "                    xc = sx + rdx\n",
        "                    yc = sy + rdy\n",
        "\n",
        "                    if 0 <= xc < w and 0 <= yc < h:\n",
        "                        # Weighted Voting\n",
        "                        accumulator[yc, xc] += (s_mags[i] * rmag)\n",
        "\n",
        "        # Smoothing\n",
        "        accumulator = cv2.GaussianBlur(accumulator, (9, 9), 2.0)\n",
        "        return accumulator\n",
        "\n",
        "    def _process_coarse_to_fine(self, scale, angle, r_table, t_w, t_h, color_mask=None):\n",
        "        # --- 1. Coarse Search (1/2 Scale) ---\n",
        "        coarse_eff_scale = scale * self.coarse_scale\n",
        "\n",
        "        # Coarse ë ˆë²¨ ë§ˆìŠ¤í¬ ì ìš©\n",
        "        final_mask_coarse = self.mask_coarse\n",
        "        if color_mask is not None:\n",
        "            mask_small = cv2.resize(color_mask, None, fx=self.coarse_scale, fy=self.coarse_scale, interpolation=cv2.INTER_NEAREST)\n",
        "            # \"ì—£ì§€ë„ ìˆê³ (True) AND ìƒ‰ê¹”ë„ ë§ëŠ”(>0) ê³³\"ë§Œ ë‚¨ê¹€\n",
        "            final_mask_coarse = self.mask_coarse & (mask_small > 0)\n",
        "\n",
        "        # ì—£ì§€ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ìŠ¤í‚µ (ì†ë„ í–¥ìƒ)\n",
        "        if not np.any(final_mask_coarse):\n",
        "            return None\n",
        "\n",
        "        coarse_r_table = self._get_rotated_r_table(r_table, angle, coarse_eff_scale)\n",
        "\n",
        "        # íˆ¬í‘œ í•¨ìˆ˜ì— 'í•©ì³ì§„ ë§ˆìŠ¤í¬'ë¥¼ ì „ë‹¬\n",
        "        acc_coarse = self._vote(\n",
        "            coarse_r_table,\n",
        "            self.grad_coarse, self.orient_coarse, final_mask_coarse\n",
        "        )\n",
        "\n",
        "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(acc_coarse)\n",
        "        if max_val < 500: return None\n",
        "\n",
        "        # Coarse ìœ„ì¹˜ -> Fine ìœ„ì¹˜ ë³€í™˜\n",
        "        center_x_coarse, center_y_coarse = max_loc\n",
        "        orig_cx = int(center_x_coarse / self.coarse_scale)\n",
        "        orig_cy = int(center_y_coarse / self.coarse_scale)\n",
        "\n",
        "        # --- 2. Fine Search (ROI Only) ---\n",
        "        margin = 30\n",
        "        fine_h, fine_w = self.grad_fine.shape\n",
        "\n",
        "        start_x = max(0, orig_cx - margin - int(t_w*scale/2))\n",
        "        start_y = max(0, orig_cy - margin - int(t_h*scale/2))\n",
        "        end_x = min(fine_w, orig_cx + margin + int(t_w*scale/2))\n",
        "        end_y = min(fine_h, orig_cy + margin + int(t_h*scale/2))\n",
        "\n",
        "        if end_x <= start_x or end_y <= start_y: return None\n",
        "\n",
        "        # ROI ì˜ë¼ë‚´ê¸°\n",
        "        grad_roi = self.grad_fine[start_y:end_y, start_x:end_x]\n",
        "        orient_roi = self.orient_fine[start_y:end_y, start_x:end_x]\n",
        "        mask_roi = self.mask_fine[start_y:end_y, start_x:end_x]\n",
        "\n",
        "        # Fine ë ˆë²¨ ë§ˆìŠ¤í¬ ì ìš© (ROI ë¶€ë¶„ë§Œ ì˜ë¼ì„œ)\n",
        "        if color_mask is not None:\n",
        "            color_mask_roi = color_mask[start_y:end_y, start_x:end_x]\n",
        "            mask_roi = mask_roi & (color_mask_roi > 0)\n",
        "\n",
        "        if not np.any(mask_roi): return None\n",
        "\n",
        "        fine_r_table = self._get_rotated_r_table(r_table, angle, scale)\n",
        "        acc_fine_roi = self._vote(fine_r_table, grad_roi, orient_roi, mask_roi)\n",
        "\n",
        "        f_min, f_max, f_loc_min, f_loc_max = cv2.minMaxLoc(acc_fine_roi)\n",
        "\n",
        "        final_cx = start_x + f_loc_max[0]\n",
        "        final_cy = start_y + f_loc_max[1]\n",
        "\n",
        "        return {\n",
        "            'scale': scale,\n",
        "            'angle': angle,\n",
        "            'votes': f_max,\n",
        "            'location': (final_cx, final_cy),\n",
        "            'box': (int(final_cx - t_w*scale//2), int(final_cy - t_h*scale//2),\n",
        "                    int(t_w*scale), int(t_h*scale))\n",
        "        }\n",
        "\n",
        "    def match(self, template_path, label, scale_range=(0.8, 1.4), scale_step=0.1, rotation_step=15, color_mask=None):\n",
        "        template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
        "        r_table, (t_w, t_h) = self._build_r_table(template)\n",
        "\n",
        "        print(f\"\\n{'='*90}\")\n",
        "        print(f\"   Optimized GHT (Rotated Table + Coarse-to-Fine): {label}\")\n",
        "        print(f\"   Scale: {scale_range} | Rot Step: {rotation_step}Â°\")\n",
        "\n",
        "        scales = np.arange(scale_range[0], scale_range[1] + 1e-5, scale_step)\n",
        "        angles = np.arange(0, 360, rotation_step)\n",
        "\n",
        "        results = Parallel(n_jobs=-1)(\n",
        "            delayed(self._process_coarse_to_fine)(scale, angle, r_table, t_w, t_h, color_mask)\n",
        "            for scale in scales\n",
        "            for angle in angles\n",
        "        )\n",
        "\n",
        "        valid_results = [r for r in results if r is not None]\n",
        "        valid_results.sort(key=lambda x: x['votes'], reverse=True)\n",
        "\n",
        "        top_results = valid_results[:3]\n",
        "\n",
        "        if not top_results:\n",
        "             print(\"   âŒ No match found.\")\n",
        "             return {'label': label, 'best_score': 0, 'best_scale': 1.0, 'best_location': (0,0), 'top_results': []}\n",
        "\n",
        "        best_res = top_results[0]\n",
        "        norm_score = min(1.0, best_res['votes'] / 100000.0)\n",
        "\n",
        "        print(f\"\\nìƒìœ„ ê²°ê³¼:\")\n",
        "        for i, res in enumerate(top_results, 1):\n",
        "            print(f\"  {i}. Scale {res['scale']:.2f}x | Angle {res['angle']}Â°| Votes {best_res['votes']:.0f}\")\n",
        "\n",
        "        center_x, center_y = best_res['location']\n",
        "        bw, bh = best_res['box'][2], best_res['box'][3]\n",
        "\n",
        "        return {\n",
        "            'label': label,\n",
        "            'best_scale': best_res['scale'],\n",
        "            'best_angle': best_res['angle'],\n",
        "            'best_score': norm_score,\n",
        "            'best_votes': best_res['votes'],\n",
        "            'best_location': (int(center_x - bw/2), int(center_y - bh/2)),\n",
        "            'best_template_size': (bw, bh),\n",
        "            'top_results': valid_results[:3]\n",
        "        }"
      ],
      "metadata": {
        "id": "Mb6_EHy8_w0r"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wrapper\n",
        "\n",
        "ì´ë¯¸ì§€ íƒ€ì…ì— ë”°ë¼ ìë™ìœ¼ë¡œ ì ì ˆí•œ ë§¤ì²˜(Matcher)ë¥¼ ì„ íƒí•˜ëŠ” Wrapper Class"
      ],
      "metadata": {
        "id": "vZpkN7IfoYNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiMatcher:\n",
        "    \"\"\"\n",
        "    ì´ë¯¸ì§€ íƒ€ì…(ì»¬ëŸ¬/í‘ë°±)ì„ ê°ì§€í•˜ì—¬ ì ì ˆí•œ Matcherë¡œ ì—°ê²°í•˜ëŠ” Wrapper í´ë˜ìŠ¤\n",
        "    \"\"\"\n",
        "    is_wrapper = True\n",
        "\n",
        "    def __init__(self, scene_path: str, **kwargs):\n",
        "        self.scene_path = scene_path\n",
        "\n",
        "        test_img = cv2.imread(scene_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "        if test_img is None:\n",
        "            raise ValueError(f\"Cannot load scene image: {scene_path}\")\n",
        "\n",
        "        is_grayscale = False\n",
        "\n",
        "        if len(test_img.shape) == 2 or (len(test_img.shape) == 3 and test_img.shape[2] == 1):\n",
        "            is_grayscale = True\n",
        "        else:\n",
        "            hsv = cv2.cvtColor(test_img, cv2.COLOR_BGR2HSV)\n",
        "            saturation = hsv[:, :, 1]\n",
        "            mean_saturation = np.mean(saturation)\n",
        "\n",
        "            if mean_saturation < 4.0:\n",
        "                is_grayscale = True\n",
        "                print(f\"[Check] 3-channel image but Low Saturation (Mean S={mean_saturation:.2f}). Treating as Grayscale.\")\n",
        "\n",
        "        if is_grayscale:\n",
        "            print(f\"ğŸ–¤ [Info] Grayscale Scene detected ({scene_path}). Using Grayscale Matcher.\")\n",
        "            self.matcher = GrayscaleChamferMatcher(scene_path, **kwargs)\n",
        "        else:\n",
        "            print(f\"ğŸ¨ [Info] Color Scene detected ({scene_path}). Using Original Color Matcher.\")\n",
        "            self.matcher = ColorGHTMatcher(scene_path)\n",
        "\n",
        "    def match(self, *args, **kwargs):\n",
        "        return self.matcher.match(*args, **kwargs)\n",
        "\n",
        "    def __getattr__(self, name):\n",
        "        return getattr(self.matcher, name)"
      ],
      "metadata": {
        "id": "0fdpGhn0pYhb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5oC0DcJcJ5w"
      },
      "source": [
        "## Detection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_all_objects(scene_path: str,\n",
        "                     template_paths: dict,\n",
        "                     method: str = 'multi',\n",
        "                     scale_range=(0.8, 1.4),\n",
        "                     scale_step=0.1,\n",
        "                     **kwargs):\n",
        "\n",
        "    if method == 'multi':\n",
        "        matcher = MultiMatcher(scene_path, **kwargs)\n",
        "        match_func = matcher.match\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown method: {method}\")\n",
        "\n",
        "    all_detections = []\n",
        "\n",
        "    print(f\"Finding All Objects using {method.upper()} method\")\n",
        "    print(f\"{'='*90}\\n\")\n",
        "\n",
        "    for label, template_path in template_paths.items():\n",
        "        print(f\"\\nğŸ” Searching for: {label}\")\n",
        "\n",
        "        result = match_func(\n",
        "            template_path=template_path,\n",
        "            label=label,\n",
        "            scale_range=scale_range,\n",
        "            scale_step=scale_step\n",
        "        )\n",
        "\n",
        "        all_detections.append(result)\n",
        "\n",
        "        score = result['best_score']\n",
        "        scale = result['best_scale']\n",
        "        angle = result.get('best_angle')\n",
        "\n",
        "        if angle is not None:\n",
        "            print(f\"   âœ“ Best score: {score:.4f} at scale {scale:.2f}x, angle {angle}Â°\")\n",
        "        else:\n",
        "            print(f\"   âœ“ Best score: {score:.4f} at scale {scale:.2f}x\")\n",
        "\n",
        "    return all_detections"
      ],
      "metadata": {
        "id": "9mCPoWhyiBdF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzYd28NxARSL"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ATO-3TX2gHnw"
      },
      "outputs": [],
      "source": [
        "def visualize_all_objects(scene_path: str,\n",
        "                         detections: list,\n",
        "                         output_path: str,\n",
        "                         method_name: str = \"Multi-Object Detection\",\n",
        "                         show_scores: bool = True):\n",
        "    # Scene ë¡œë“œ\n",
        "    scene = cv2.imread(scene_path)\n",
        "    if scene is None:\n",
        "        raise ValueError(f\"Cannot load scene image: {scene_path}\")\n",
        "\n",
        "    scene_h, scene_w = scene.shape[:2]\n",
        "\n",
        "    # Scene íŒŒì¼ëª… ì¶”ì¶œ (íŒŒì¼ëª…ì— í¬í•¨ì‹œí‚¬ ìš©ë„)\n",
        "    scene_name = os.path.splitext(os.path.basename(scene_path))[0]\n",
        "\n",
        "    # ìƒ‰ìƒ íŒ”ë ˆíŠ¸\n",
        "    colors = [\n",
        "        (0, 255, 0),      # Green\n",
        "        (255, 0, 0),      # Blue\n",
        "        (0, 165, 255),    # Orange\n",
        "        (255, 0, 255),    # Magenta\n",
        "        (0, 255, 255),    # Yellow\n",
        "        (255, 255, 0),    # Cyan\n",
        "        (128, 0, 128),    # Purple\n",
        "        (255, 128, 0),    # Sky Blue\n",
        "    ]\n",
        "\n",
        "    # ê° ê°ì§€ ê²°ê³¼ ê·¸ë¦¬ê¸°\n",
        "    for idx, result in enumerate(detections):\n",
        "        label = result['label']\n",
        "        location = result['best_location']\n",
        "        template_size = result['best_template_size']\n",
        "        score = result['best_score']\n",
        "        scale = result['best_scale']\n",
        "        angle = result.get('best_angle', 0) # angle ì •ë³´ê°€ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì²˜ë¦¬\n",
        "\n",
        "        x, y = int(location[0]), int(location[1])\n",
        "        w, h = int(template_size[0]), int(template_size[1])\n",
        "\n",
        "        color = colors[idx % len(colors)]\n",
        "\n",
        "        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°\n",
        "        if x >= 0 and y >= 0 and x + w <= scene_w and y + h <= scene_h:\n",
        "            cv2.rectangle(scene, (x, y), (x + w, y + h), color, 2)\n",
        "\n",
        "            # ë¼ë²¨ í…ìŠ¤íŠ¸ ì¤€ë¹„\n",
        "            if show_scores:\n",
        "                angle_text = f\", {angle}Â°\" if angle != 0 else \"\"\n",
        "                text = f\"{label} ({scale:.1f}x{angle_text}, {score:.2f})\"\n",
        "            else:\n",
        "                text = f\"{label}\"\n",
        "\n",
        "            # í…ìŠ¤íŠ¸ ë°°ê²½\n",
        "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "            font_scale = 0.4\n",
        "            thickness = 2\n",
        "\n",
        "            text_size = cv2.getTextSize(text, font, font_scale, thickness)[0]\n",
        "\n",
        "            # í…ìŠ¤íŠ¸ ìœ„ì¹˜\n",
        "            text_x = x\n",
        "            text_y = y - 5 if y - 5 > 15 else y + h + 15\n",
        "\n",
        "            # í…ìŠ¤íŠ¸ ë°°ê²½ ê·¸ë¦¬ê¸°\n",
        "            cv2.rectangle(scene,\n",
        "                         (text_x, text_y - text_size[1] - 4),\n",
        "                         (text_x + text_size[0] + 4, text_y + 4),\n",
        "                         color, -1)\n",
        "\n",
        "            # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°\n",
        "            cv2.putText(scene, text, (text_x + 2, text_y),\n",
        "                       font, font_scale, (255, 255, 255), thickness)\n",
        "\n",
        "    # ë©”ì„œë“œ ì œëª©\n",
        "    title = f\"{method_name} - {len(detections)} objects detected - Scene: {scene_name}\"\n",
        "    title_font_scale = 0.6\n",
        "    title_thickness = 2\n",
        "\n",
        "    title_size = cv2.getTextSize(title, cv2.FONT_HERSHEY_SIMPLEX, title_font_scale, title_thickness)[0]\n",
        "\n",
        "    # ì œëª© ë°°ê²½\n",
        "    cv2.rectangle(scene, (5, 5), (15 + title_size[0], 15 + title_size[1]), (0, 0, 0), -1)\n",
        "    # ì œëª© í…ìŠ¤íŠ¸\n",
        "    cv2.putText(scene, title, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, title_font_scale, (0, 255, 255), title_thickness)\n",
        "\n",
        "    # ê²°ê³¼ ì €ì¥\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    cv2.imwrite(output_path, scene)\n",
        "    print()\n",
        "    print(f\"âœ“ Visualization saved: {output_path}\")\n",
        "\n",
        "    return scene"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "Fd6B_oFNm-gx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "a4wlj8MheaQS"
      },
      "outputs": [],
      "source": [
        "def auto_find_templates(scene_path, template_dir):\n",
        "    \"\"\"\n",
        "    Scene íŒŒì¼ ê²½ë¡œì™€ í…œí”Œë¦¿ ë””ë ‰í† ë¦¬ì—ì„œ ìë™ìœ¼ë¡œ í…œí”Œë¦¿ ì°¾ê¸°\n",
        "    \"\"\"\n",
        "    # Scene íŒŒì¼ëª… ì¶”ì¶œ\n",
        "    scene_filename = os.path.basename(scene_path)\n",
        "    scene_prefix = os.path.splitext(scene_filename)[0]\n",
        "\n",
        "    # í…œí”Œë¦¿ ë””ë ‰í† ë¦¬ì—ì„œ í•´ë‹¹ sceneì˜ í…œí”Œë¦¿ ì°¾ê¸°\n",
        "    template_paths = {}\n",
        "\n",
        "    # íŒ¨í„´: scene_prefix-*.jpg\n",
        "    pattern = os.path.join(template_dir, f'{scene_prefix}-*.*')\n",
        "\n",
        "    for filepath in glob.glob(pattern):\n",
        "        filename = os.path.basename(filepath)\n",
        "\n",
        "        # í™•ì¥ìê°€ ì´ë¯¸ì§€ íŒŒì¼ì¸ì§€ í™•ì¸\n",
        "        if not filename.lower().endswith(('.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG')):\n",
        "            continue\n",
        "\n",
        "        # ë¼ë²¨ ì¶”ì¶œ\n",
        "        name_without_ext = os.path.splitext(filename)[0]\n",
        "        label = name_without_ext.replace(f'{scene_prefix}-', '', 1)\n",
        "\n",
        "        template_paths[label] = filepath\n",
        "\n",
        "    return template_paths"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_all_methods(scene_path: str,\n",
        "                       template_paths: dict,\n",
        "                       output_dir: str,\n",
        "                       scale_range=(0.5, 2.0),\n",
        "                       scale_step=0.2,\n",
        "                       methods=('multi',)):\n",
        "    \"\"\"\n",
        "    ì—¬ëŸ¬ ë°©ë²• ë¹„êµ\n",
        "    (ìµœì¢…ì ìœ¼ë¡œ multi(Chamfer for Grayscale, GHT for Color) methodë§Œ ì´ìš©í•¨)\n",
        "    \"\"\"\n",
        "    scene_name = os.path.splitext(os.path.basename(scene_path))[0]\n",
        "    all_results = {}\n",
        "\n",
        "    for method in methods:\n",
        "        detections = find_all_objects(\n",
        "            scene_path=scene_path,\n",
        "            template_paths=template_paths,\n",
        "            method=method,\n",
        "            scale_range=scale_range,\n",
        "            scale_step=scale_step\n",
        "        )\n",
        "\n",
        "        all_results[method] = detections\n",
        "\n",
        "        output_path = os.path.join(output_dir, f\"{scene_name}_all_objects_{method}.png\")\n",
        "        visualize_all_objects(\n",
        "            scene_path=scene_path,\n",
        "            detections=detections,\n",
        "            output_path=output_path,\n",
        "            method_name=f\"{method.upper()} Matching\"\n",
        "        )\n",
        "\n",
        "    # methods ê°œìˆ˜ì— ë§ì¶° ë¹„êµ ì´ë¯¸ì§€ ìƒì„± (methodsê°€ 1ê°œë©´ ë¹„êµ ì´ë¯¸ì§€ë„ 1ê°œ í­)\n",
        "    scene = cv2.imread(scene_path)\n",
        "    scene_h, scene_w = scene.shape[:2]\n",
        "\n",
        "    comparison = np.zeros((scene_h, scene_w * len(methods), 3), dtype=np.uint8)\n",
        "\n",
        "    for col_idx, method in enumerate(methods):\n",
        "        result_path = os.path.join(output_dir, f\"{scene_name}_all_objects_{method}.png\")\n",
        "        result_img = cv2.imread(result_path)\n",
        "        if result_img is None:\n",
        "            continue\n",
        "        comparison[:, col_idx*scene_w:(col_idx+1)*scene_w] = result_img\n",
        "\n",
        "    comparison_path = os.path.join(output_dir, f\"{scene_name}_comparison_all_methods.png\")\n",
        "    cv2.imwrite(comparison_path, comparison)\n",
        "\n",
        "    return all_results"
      ],
      "metadata": {
        "id": "ObsJOqbdm9vr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "possible_exts = [\"png\", \"PNG\", \"jpg\", \"JPG\", \"jpeg\", \"JPEG\"]\n",
        "\n",
        "def find_template_file(scene_id, template_dir, template_name):\n",
        "    base = f\"{scene_id}-{template_name}\"\n",
        "    for ext in possible_exts:\n",
        "        fp = os.path.join(template_dir, f\"{base}.{ext}\")\n",
        "        if os.path.exists(fp):\n",
        "            return fp\n",
        "    return None\n",
        "\n",
        "def get_template_radius(scene_id, template_dir, template_name):\n",
        "    file_path = find_template_file(scene_id, template_dir, template_name)\n",
        "    if file_path is None or (not os.path.exists(file_path)):\n",
        "        print(f\"[ê²½ê³ ] í…œí”Œë¦¿ ì´ë¯¸ì§€ ì—†ìŒ: {scene_id}-{template_name} â†’ ê¸°ë³¸ ë°˜ì§€ë¦„ 40\")\n",
        "        return 40\n",
        "\n",
        "    img = cv2.imread(file_path)\n",
        "    if img is None:\n",
        "        print(f\"[ê²½ê³ ] í…œí”Œë¦¿ ì½ê¸° ì‹¤íŒ¨: {file_path} â†’ ê¸°ë³¸ ë°˜ì§€ë¦„ 40\")\n",
        "        return 40\n",
        "\n",
        "    h, w = img.shape[:2]\n",
        "    radius = int(max(w, h) * 0.5)\n",
        "    radius = min(radius, 120)\n",
        "    return radius\n",
        "\n",
        "def calculate_iou(boxA, boxB):\n",
        "    xA, yA, wA, hA = boxA\n",
        "    xB, yB, wB, hB = boxB\n",
        "    A = (xA, yA, xA + wA, yA + hA)\n",
        "    B = (xB, yB, xB + wB, yB + hB)\n",
        "\n",
        "    x1 = max(A[0], B[0]); y1 = max(A[1], B[1])\n",
        "    x2 = min(A[2], B[2]); y2 = min(A[3], B[3])\n",
        "\n",
        "    iw = max(0, x2 - x1)\n",
        "    ih = max(0, y2 - y1)\n",
        "    inter = iw * ih\n",
        "\n",
        "    areaA = wA * hA\n",
        "    areaB = wB * hB\n",
        "    denom = (areaA + areaB - inter)\n",
        "    if denom <= 0:\n",
        "        return 0.0\n",
        "    return inter / denom"
      ],
      "metadata": {
        "id": "17jYzPg7nCjV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_dashed_circle(img, center, radius, color, thickness=2, dash_len=10):\n",
        "    x, y = center\n",
        "    for angle in range(0, 360, dash_len * 2):\n",
        "        cv2.ellipse(img, (x, y), (radius, radius), 0, angle, angle + dash_len, color, thickness)\n",
        "\n",
        "def visualize_combined_results(scene_path: str,\n",
        "                               detections: list,\n",
        "                               df_scene_gt: pd.DataFrame,\n",
        "                               output_path: str,\n",
        "                               template_dir: str,\n",
        "                               scene_id: str,\n",
        "                               iou_threshold: float = 0.5):\n",
        "    scene = cv2.imread(scene_path)\n",
        "    if scene is None:\n",
        "        raise ValueError(f\"Cannot load scene image: {scene_path}\")\n",
        "\n",
        "    scene_h, scene_w = scene.shape[:2]\n",
        "\n",
        "    COLOR_TP = (255, 0, 0)       # Blue\n",
        "    COLOR_FP = (0, 0, 255)       # Red\n",
        "    COLOR_FN = (100, 100, 100)   # Dark Gray\n",
        "\n",
        "    matched_gt_indices = set()\n",
        "\n",
        "\n",
        "# 1. Detection ìˆœíšŒ ë° ë§¤ì¹­ í™•ì¸\n",
        "    for det in detections:\n",
        "        label = det['label']\n",
        "        x, y = map(int, det['best_location'])\n",
        "        w, h = map(int, det['best_template_size'])\n",
        "\n",
        "        # ì¤‘ì‹¬ì  ê³„ì‚°\n",
        "        det_cx, det_cy = x + w / 2, y + h / 2\n",
        "\n",
        "        # í•´ë‹¹ ë¼ë²¨ì˜ GT í›„ë³´êµ° ì¶”ì¶œ\n",
        "        gt_candidates = df_scene_gt[df_scene_gt['template'] == label]\n",
        "\n",
        "        is_correct = False\n",
        "\n",
        "        # GT í›„ë³´ë“¤ê³¼ ê±°ë¦¬ ë¹„êµ\n",
        "        for idx, row in gt_candidates.iterrows():\n",
        "            gt_x, gt_y = int(row['x']), int(row['y'])\n",
        "            radius = get_template_radius(scene_id, template_dir, label)\n",
        "\n",
        "            # ê±°ë¦¬ ê³„ì‚°\n",
        "            dist = ((det_cx - gt_x)**2 + (det_cy - gt_y)**2)**0.5\n",
        "\n",
        "            # ì •ë‹µ íŒë³„ (0.5R ì´ë‚´)\n",
        "            if dist <= radius * 0.5:\n",
        "                is_correct = True\n",
        "                matched_gt_indices.add(idx)\n",
        "\n",
        "        if is_correct:\n",
        "            # True Positive (Blue Box)\n",
        "            cv2.rectangle(scene, (x, y), (x + w, y + h), COLOR_TP, 3)\n",
        "            cv2.putText(scene, f\"{label}\", (x, y - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, COLOR_TP, 2)\n",
        "        else:\n",
        "            # False Positive (Red Box w/ X mark)\n",
        "            cv2.line(scene, (x, y), (x + w, y + h), COLOR_FP, 3)\n",
        "            cv2.line(scene, (x + w, y), (x, y + h), COLOR_FP, 3)\n",
        "            cv2.putText(scene, f\"{label}\", (x, y - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, COLOR_FP, 2)\n",
        "\n",
        "    # 2. ë¯¸ê²€ì¶œ GT (False Negative) ìˆœíšŒ\n",
        "    # matched_gt_indicesì— ì—†ëŠ” GTë§Œ íšŒìƒ‰ ì ì„ ìœ¼ë¡œ ê·¸ë¦¼\n",
        "    for idx, row in df_scene_gt.iterrows():\n",
        "        if idx not in matched_gt_indices:\n",
        "            gt_x, gt_y = int(row['x']), int(row['y'])\n",
        "            template_name = row['template']\n",
        "            radius = get_template_radius(scene_id, template_dir, template_name)\n",
        "\n",
        "            draw_dashed_circle(scene, (gt_x, gt_y), radius, COLOR_FN, thickness=2, dash_len=10)\n",
        "            cv2.putText(scene, f\"{template_name}\", (gt_x - radius, gt_y - radius - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLOR_FN, 2)\n",
        "\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    cv2.imwrite(output_path, scene)\n",
        "    print(f\"âœ“ Visualization saved: {output_path}\")\n",
        "    return scene\n",
        "\n",
        "def parse_scene_gt(df_gt_all, scene_id):\n",
        "    df_scene = df_gt_all[df_gt_all['scene'] == scene_id].copy()\n",
        "    if df_scene.empty:\n",
        "        return df_scene\n",
        "\n",
        "    split_coords = df_scene['px'].astype(str).str.split(',', expand=True)\n",
        "    df_scene['x'] = split_coords[0].str.strip().astype(int)\n",
        "    df_scene['y'] = split_coords[1].str.strip().astype(int)\n",
        "    return df_scene\n",
        "\n",
        "def evaluate_one_scene(scene_path, template_dir, output_dir,\n",
        "                       df_gt_all=None, df_scene_gt=None, scale_range=(0.7, 1.0), scale_step=0.1,\n",
        "                       iou_threshold=0.5):\n",
        "    scene_id = os.path.splitext(os.path.basename(scene_path))[0]\n",
        "    scene_out_dir = os.path.join(output_dir, scene_id)\n",
        "    os.makedirs(scene_out_dir, exist_ok=True)\n",
        "\n",
        "    # í…œí”Œë¦¿ ìë™ íƒìƒ‰\n",
        "    template_paths = auto_find_templates(scene_path, template_dir)\n",
        "    if not template_paths:\n",
        "        print(f\"âš ï¸ [{scene_id}] í…œí”Œë¦¿ì´ ì—†ì–´ ìŠ¤í‚µí•©ë‹ˆë‹¤.\")\n",
        "        return None\n",
        "\n",
        "    # íƒì§€ ì‹¤í–‰ (í˜„ì¬ ghtë§Œ)\n",
        "    results = compare_all_methods(\n",
        "        scene_path=scene_path,\n",
        "        template_paths=template_paths,\n",
        "        output_dir=scene_out_dir,\n",
        "        scale_range=scale_range,\n",
        "        scale_step=scale_step,\n",
        "        methods=('multi',)\n",
        "    )\n",
        "\n",
        "    detections = results['multi']  # list\n",
        "\n",
        "    # GT ì—†ìœ¼ë©´ íƒì§€ë§Œ ì €ì¥í•˜ê³  ì¢…ë£Œ\n",
        "    if df_scene_gt is None or df_scene_gt.empty:\n",
        "        print(f\"âš ï¸ [{scene_id}] GTê°€ ì—†ì–´ í‰ê°€ ìŠ¤í‚µ (íƒì§€ë§Œ ì €ì¥).\")\n",
        "        return {\n",
        "            'scene_id': scene_id,\n",
        "            'n_templates': len(template_paths),\n",
        "            'accuracy': None,\n",
        "            'matched': '',\n",
        "            'unmatched': '',\n",
        "            'metrics_csv': None,\n",
        "            '_correct_cnt': 0,\n",
        "            '_total_cnt': 0\n",
        "        }\n",
        "\n",
        "    df_scene = df_scene_gt\n",
        "\n",
        "    # Distance/IoU ê³„ì‚°\n",
        "    distances = []\n",
        "    ious = []\n",
        "\n",
        "    for det in detections:\n",
        "        label = det['label']\n",
        "        x_det, y_det = det['best_location']\n",
        "        w_det, h_det = det['best_template_size']\n",
        "\n",
        "        cx_det = x_det + w_det / 2\n",
        "        cy_det = y_det + h_det / 2\n",
        "\n",
        "        gt_entry = df_scene[df_scene['template'] == label]\n",
        "        if gt_entry.empty:\n",
        "            continue\n",
        "\n",
        "        cx_gt = int(gt_entry['x'].iloc[0])\n",
        "        cy_gt = int(gt_entry['y'].iloc[0])\n",
        "\n",
        "        dist = float(np.sqrt((cx_det - cx_gt) ** 2 + (cy_det - cy_gt) ** 2))\n",
        "        distances.append((label, dist))\n",
        "\n",
        "        # IoU (GTëŠ” ì›->bbox ê·¼ì‚¬)\n",
        "        radius = get_template_radius(scene_id, template_dir, label)\n",
        "        gt_bbox = (cx_gt - radius, cy_gt - radius, 2 * radius, 2 * radius)\n",
        "        det_box = (int(x_det), int(y_det), int(w_det), int(h_det))\n",
        "        iou = float(calculate_iou(det_box, gt_bbox))\n",
        "        ious.append((label, iou))\n",
        "\n",
        "    # ê²°ê³¼ DF\n",
        "    dist_map = {k: v for k, v in distances}\n",
        "    iou_map = {k: v for k, v in ious}\n",
        "\n",
        "    final_rows = []\n",
        "    for det in detections:\n",
        "        label = det['label']\n",
        "        gt_entry = df_scene[df_scene['template'] == label]\n",
        "        if gt_entry.empty:\n",
        "            gt_px = \"N/A\"\n",
        "        else:\n",
        "            gt_px = f\"{int(gt_entry['x'].iloc[0])}, {int(gt_entry['y'].iloc[0])}\"\n",
        "\n",
        "        final_rows.append({\n",
        "            'scene_id': scene_id,\n",
        "            'template_name': label,\n",
        "            'ground_truth_px': gt_px,\n",
        "            'distance': f\"{dist_map.get(label, 'N/A'):.2f}\" if label in dist_map else \"N/A\",\n",
        "            'iou': f\"{iou_map.get(label, 'N/A'):.4f}\" if label in iou_map else \"N/A\"\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(final_rows)\n",
        "\n",
        "    metrics_csv_path = os.path.join(scene_out_dir, f\"{scene_id}_detection_metrics.csv\")\n",
        "    results_df.to_csv(metrics_csv_path, index=False)\n",
        "    print(f\"âœ“ Detection metrics saved to: {metrics_csv_path}\")\n",
        "\n",
        "    # Combined ì‹œê°í™”\n",
        "    combined_output_path = os.path.join(scene_out_dir, f\"{scene_id}_det_and_gt_combined.png\")\n",
        "    visualize_combined_results(\n",
        "        scene_path=scene_path,\n",
        "        detections=detections,\n",
        "        df_scene_gt=df_scene,\n",
        "        output_path=combined_output_path,\n",
        "        template_dir=template_dir,\n",
        "        scene_id=scene_id,\n",
        "        iou_threshold=iou_threshold\n",
        "    )\n",
        "\n",
        "    # Accuracy (0.5R)\n",
        "    correct, wrong = [], []\n",
        "    for _, row in results_df.iterrows():\n",
        "        name = row['template_name']\n",
        "        dist_val = row['distance']\n",
        "\n",
        "        distance = float(dist_val) if dist_val != \"N/A\" else float('inf')\n",
        "        radius = get_template_radius(scene_id, template_dir, name)\n",
        "\n",
        "        if distance <= (radius * 0.5):\n",
        "            correct.append(name)\n",
        "        else:\n",
        "            wrong.append(name)\n",
        "\n",
        "    total = len(results_df)\n",
        "    acc = (len(correct) / total) * 100 if total > 0 else 0.0\n",
        "\n",
        "    print(f\"[{scene_id}] Accuracy(<=0.5R): {acc:.2f}% | Matched: {len(correct)}/{total}\")\n",
        "\n",
        "    return {\n",
        "        'scene_id': scene_id,\n",
        "        'n_templates': len(template_paths),\n",
        "        'accuracy': acc,\n",
        "        'matched': ', '.join(correct) if correct else '',\n",
        "        'unmatched': ', '.join(wrong) if wrong else '',\n",
        "        'metrics_csv': metrics_csv_path,\n",
        "        '_correct_cnt': len(correct),\n",
        "        '_total_cnt': total\n",
        "    }"
      ],
      "metadata": {
        "id": "BFOyo59-nEqL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_df_scene_gt(scene_id: str, gt_dir: str, gt_cache: dict):\n",
        "    prefix = scene_id[:2].lower()\n",
        "    gt_csv_path = os.path.join(gt_dir, f\"{prefix}-ground-truth.csv\")\n",
        "\n",
        "    if prefix not in gt_cache:\n",
        "        if not os.path.exists(gt_csv_path):\n",
        "            print(f\"âš ï¸ GT CSV ì—†ìŒ: {gt_csv_path}\")\n",
        "            gt_cache[prefix] = pd.DataFrame(columns=['scene','template','px'])\n",
        "        else:\n",
        "            gt_cache[prefix] = pd.read_csv(gt_csv_path)\n",
        "\n",
        "    df_all = gt_cache[prefix]\n",
        "    if df_all.empty:\n",
        "        return df_all.copy()\n",
        "\n",
        "    # CSVì˜ scene ì»¬ëŸ¼ê³¼ ë¹„êµ\n",
        "    df_scene = df_all[df_all['scene'] == scene_id].copy()\n",
        "    if df_scene.empty:\n",
        "        return df_scene\n",
        "\n",
        "    # px \"378, 50\" -> x,y\n",
        "    split_coords = df_scene['px'].astype(str).str.split(',', expand=True)\n",
        "    df_scene['x'] = split_coords[0].str.strip().astype(int)\n",
        "    df_scene['y'] = split_coords[1].str.strip().astype(int)\n",
        "    return df_scene"
      ],
      "metadata": {
        "id": "2AVuMk6qCgFC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_all_scenes_batch(scenes_dir, template_dir, output_dir,\n",
        "                         gt_dir=None, scale_range=(0.7, 1.0), scale_step=0.1,\n",
        "                         iou_threshold=0.5):\n",
        "\n",
        "    scene_files = []\n",
        "    scene_files = sorted(\n",
        "        glob.glob(os.path.join(scenes_dir, '*.jpg')) +\n",
        "        glob.glob(os.path.join(scenes_dir, '*.JPG')) +\n",
        "        glob.glob(os.path.join(scenes_dir, '*.png')) +\n",
        "        glob.glob(os.path.join(scenes_dir, '*.PNG')) +\n",
        "        glob.glob(os.path.join(scenes_dir, '*.jpeg')) +\n",
        "        glob.glob(os.path.join(scenes_dir, '*.JPEG'))\n",
        "    )\n",
        "\n",
        "    scene_files = scene_files[:]\n",
        "    print(\"âœ… Run:\", [os.path.basename(p) for p in scene_files])\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # prefixë³„ GT csv ìºì‹œ\n",
        "    gt_cache = {}\n",
        "\n",
        "    summary_rows = []\n",
        "\n",
        "    # ì „ì²´ ì •í™•ë„ ê³„ì‚°ìš© ëˆ„ì  ì¹´ìš´í„° (ë°°ì¹˜ ë‹¨ìœ„)\n",
        "    total_correct = 0\n",
        "    total_total = 0\n",
        "\n",
        "    for scene_path in scene_files:\n",
        "        scene_id = os.path.splitext(os.path.basename(scene_path))[0]\n",
        "        print(f\"\\n{'='*90}\\nğŸš€ Processing: {scene_id}\\n{'='*90}\")\n",
        "\n",
        "        # scene_id prefixì— ë§ëŠ” GT ë¡œë“œ\n",
        "        df_scene_gt = None\n",
        "        if gt_dir is not None:\n",
        "            df_scene_gt = get_df_scene_gt(scene_id, gt_dir, gt_cache)\n",
        "\n",
        "        try:\n",
        "            info = evaluate_one_scene(\n",
        "                scene_path=scene_path,\n",
        "                template_dir=template_dir,\n",
        "                output_dir=output_dir,\n",
        "                df_scene_gt=df_scene_gt,\n",
        "                scale_range=scale_range,\n",
        "                scale_step=scale_step,\n",
        "                iou_threshold=iou_threshold\n",
        "            )\n",
        "\n",
        "            if info is None:\n",
        "                continue\n",
        "\n",
        "            # ë°°ì¹˜ ì „ì²´ ì •í™•ë„ìš© ëˆ„ì \n",
        "            total_correct += info.get('_correct_cnt', 0)\n",
        "            total_total   += info.get('_total_cnt', 0)\n",
        "\n",
        "            # summary row (total_accuracyëŠ” ë‚˜ì¤‘ì— í•œ ë²ˆì— ë„£ìŒ)\n",
        "            summary_rows.append({\n",
        "                'scene_id': info['scene_id'],\n",
        "                'n_templates': info['n_templates'],\n",
        "                'accuracy': info['accuracy'],\n",
        "                'matched': info['matched'],\n",
        "                'unmatched': info['unmatched'],\n",
        "                'metrics_csv': info['metrics_csv'],\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ [{scene_id}] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
        "            summary_rows.append({\n",
        "                'scene_id': scene_id,\n",
        "                'n_templates': None,\n",
        "                'accuracy': None,\n",
        "                'matched': '',\n",
        "                'unmatched': '',\n",
        "                'metrics_csv': None,\n",
        "            })\n",
        "\n",
        "    # ë°°ì¹˜ ì „ì²´ ì •í™•ë„ê³„ì‚°\n",
        "    total_acc = (total_correct / total_total * 100) if total_total > 0 else None\n",
        "\n",
        "    summary_df = pd.DataFrame(summary_rows)\n",
        "\n",
        "    # ëª¨ë“  í–‰ì— ë™ì¼í•œ total_accuracy ë„£ê¸°\n",
        "    summary_df['total_accuracy'] = total_acc\n",
        "\n",
        "    # ì»¬ëŸ¼ ìˆœì„œ ì •ë ¬\n",
        "    summary_df = summary_df[['scene_id', 'n_templates', 'accuracy', 'matched', 'unmatched', 'total_accuracy', 'metrics_csv']]\n",
        "\n",
        "    summary_csv = os.path.join(output_dir, \"batch_summary.csv\")\n",
        "    summary_df.to_csv(summary_csv, index=False)\n",
        "    print(f\"\\nâœ… Batch summary saved: {summary_csv}\")\n",
        "    print(f\"âœ… Total Accuracy (all scenes): {total_acc if total_acc is not None else 'N/A'}\")\n",
        "\n",
        "    return summary_df"
      ],
      "metadata": {
        "id": "1Svmyvx2nFCj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main"
      ],
      "metadata": {
        "id": "0bUD3xrnRRK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scenes_dir = '/content/Solving-Hidden-Picture-Puzzle/test'\n",
        "template_dir = '/content/Solving-Hidden-Picture-Puzzle/dataset/templates'\n",
        "gt_dir = '/content/Solving-Hidden-Picture-Puzzle/dataset/ground-truth'\n",
        "output_dir = '/content/Solving-Hidden-Picture-Puzzle/test_result'\n",
        "\n",
        "RANGE = (0.7, 1.3)\n",
        "STEP = 0.1\n",
        "\n",
        "summary_df = run_all_scenes_batch(\n",
        "    scenes_dir=scenes_dir,\n",
        "    template_dir=template_dir,\n",
        "    output_dir=output_dir,\n",
        "    gt_dir=gt_dir,\n",
        "    scale_range=RANGE,\n",
        "    scale_step=STEP,\n",
        "    iou_threshold=0.5\n",
        ")\n",
        "\n",
        "display(summary_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "_y0k8BIFnGZY",
        "outputId": "b2e325bb-1bac-4579-ea33-fc641ea5ca7b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Run: ['ce-14.JPG', 'ge-07.jpg']\n",
            "\n",
            "==========================================================================================\n",
            "ğŸš€ Processing: ce-14\n",
            "==========================================================================================\n",
            "ğŸ¨ [Info] Color Scene detected (/content/Solving-Hidden-Picture-Puzzle/test/ce-14.JPG). Using Original Color Matcher.\n",
            "Finding All Objects using MULTI method\n",
            "==========================================================================================\n",
            "\n",
            "\n",
            "ğŸ” Searching for: fried chicken\n",
            "\n",
            "==========================================================================================\n",
            "   Optimized GHT (Rotated Table + Coarse-to-Fine): fried chicken\n",
            "   Scale: (0.7, 1.3) | Rot Step: 15Â°\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-660367747.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mSTEP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m summary_df = run_all_scenes_batch(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mscenes_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscenes_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtemplate_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemplate_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-886012438.py\u001b[0m in \u001b[0;36mrun_all_scenes_batch\u001b[0;34m(scenes_dir, template_dir, output_dir, gt_dir, scale_range, scale_step, iou_threshold)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             info = evaluate_one_scene(\n\u001b[0m\u001b[1;32m     40\u001b[0m                 \u001b[0mscene_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscene_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mtemplate_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemplate_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-938798543.py\u001b[0m in \u001b[0;36mevaluate_one_scene\u001b[0;34m(scene_path, template_dir, output_dir, df_gt_all, df_scene_gt, scale_range, scale_step, iou_threshold)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# íƒì§€ ì‹¤í–‰ (í˜„ì¬ ghtë§Œ)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     results = compare_all_methods(\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mscene_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscene_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mtemplate_paths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemplate_paths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-377331365.py\u001b[0m in \u001b[0;36mcompare_all_methods\u001b[0;34m(scene_path, template_paths, output_dir, scale_range, scale_step, methods)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         detections = find_all_objects(\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mscene_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscene_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mtemplate_paths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemplate_paths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3763003620.py\u001b[0m in \u001b[0;36mfind_all_objects\u001b[0;34m(scene_path, template_paths, method, scale_range, scale_step, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nğŸ” Searching for: {label}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         result = match_func(\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mtemplate_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemplate_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-471544689.py\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3136068499.py\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(self, template_path, label, scale_range, scale_step, rotation_step, color_mask)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mangles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m360\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         results = Parallel(n_jobs=-1)(\n\u001b[0m\u001b[1;32m    198\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_coarse_to_fine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscales\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "tIz1xyHNtPgJ",
        "Ny1C65qahd6j",
        "_VHrf79G6r3i",
        "vZpkN7IfoYNA",
        "K5oC0DcJcJ5w"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}