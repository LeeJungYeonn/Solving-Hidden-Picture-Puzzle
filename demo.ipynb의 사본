{"cells":[{"cell_type":"markdown","source":["# Demo\n","@ Team 1"],"metadata":{"id":"4uSNLNpqCTGJ"}},{"cell_type":"markdown","source":["## Setting"],"metadata":{"id":"yujvurs5Rmem"}},{"cell_type":"code","source":["# Optional: Mount Google Drive to persist results\n","# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"SK7tqYaqPEu-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MPVKGD2_7nma","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765639205140,"user_tz":-540,"elapsed":2740,"user":{"displayName":"â€ì´ì •ì—°(ì¸ê³µì§€ëŠ¥ëŒ€í•™ ì¸ê³µì§€ëŠ¥í•™ê³¼)","userId":"14307825210431520220"}},"outputId":"261fc0b6-8d05-4286-8668-1d142af5a7ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","import sys\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fE4VKFR86CRU"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import os\n","import glob\n","from scipy.ndimage import distance_transform_edt\n","from joblib import Parallel, delayed\n","import multiprocessing\n","import pandas as pd\n","import cv2.ximgproc"]},{"cell_type":"code","source":["base_dir = os.getcwd()\n","\n","scenes_dir = os.path.join(base_dir, 'test')\n","template_dir = os.path.join(base_dir, 'dataset', 'templates')\n","gt_dir = os.path.join(base_dir, 'dataset', 'ground-truth')\n","output_dir = os.path.join(base_dir, 'result2')\n","\n","os.makedirs(OUTPUT_DIR, exist_ok=True)"],"metadata":{"id":"VaNtJj33PWKl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ErrqA27Ms5OF"},"source":["## Matching Algorithms"]},{"cell_type":"markdown","source":["### Grayscale Chamfer Matching"],"metadata":{"id":"tIz1xyHNtPgJ"}},{"cell_type":"code","source":["class GrayscaleChamferMatcher:\n","    def __init__(self, scene_path: str, truncation_dist=40.0):\n","        self.scene = cv2.imread(scene_path, cv2.IMREAD_GRAYSCALE)\n","        if self.scene is None:\n","            raise ValueError(f\"Failed to load scene: {scene_path}\")\n","\n","        self.truncation_dist = truncation_dist\n","        self.num_ori_bins = 8\n","        self.ori_bin_angle = 180.0 / self.num_ori_bins\n","\n","        self.edges_fine, self.orient_map_fine = self._extract_edges_and_orientation_adaptive(self.scene)\n","        self.dir_dist_maps_fine = self._build_truncated_directional_distance_maps(\n","            self.edges_fine, self.orient_map_fine\n","        )\n","        self.integral_edges_fine = cv2.integral(self.edges_fine.astype(np.float32) / 255.0)\n","\n","        self.coarse_scale = 0.5\n","        scene_small = cv2.resize(self.scene, None, fx=self.coarse_scale, fy=self.coarse_scale)\n","\n","        self.edges_coarse, self.orient_map_coarse = self._extract_edges_and_orientation_adaptive(scene_small)\n","        self.dir_dist_maps_coarse = self._build_truncated_directional_distance_maps(\n","            self.edges_coarse, self.orient_map_coarse\n","        )\n","        self.integral_edges_coarse = cv2.integral(self.edges_coarse.astype(np.float32) / 255.0)\n","\n","    def _extract_edges_and_orientation_adaptive(self, img):\n","        \"\"\"\n","        Sceneìš©: Canny(50,150) + Morph + Skeleton\n","        \"\"\"\n","        blurred = cv2.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)\n","\n","        edges = cv2.Canny(blurred, 50, 150, L2gradient=True)\n","        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n","        edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel, iterations=1)\n","\n","        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(edges, connectivity=8)\n","        clean_edges = np.zeros_like(edges)\n","        for i in range(1, num_labels):\n","            if stats[i, cv2.CC_STAT_AREA] >= 10:\n","                clean_edges[labels == i] = 255\n","\n","        skeleton = np.zeros(clean_edges.shape, np.uint8)\n","        img_temp = clean_edges.copy()\n","        element = cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3))\n","\n","        while True:\n","            eroded = cv2.erode(img_temp, element)\n","            temp = cv2.dilate(eroded, element)\n","            temp = cv2.subtract(img_temp, temp)\n","            skeleton = cv2.bitwise_or(skeleton, temp)\n","            img_temp = eroded.copy()\n","            if cv2.countNonZero(img_temp) == 0:\n","                break\n","\n","        edges = skeleton\n","\n","        gx = cv2.Sobel(img, cv2.CV_32F, 1, 0, ksize=3)\n","        gy = cv2.Sobel(img, cv2.CV_32F, 0, 1, ksize=3)\n","        grad_angle = np.rad2deg(np.arctan2(gy, gx))\n","        grad_angle[grad_angle < 0] += 180.0\n","\n","        orient_map = np.full(grad_angle.shape, -1, dtype=np.float32)\n","        orient_map[edges > 0] = grad_angle[edges > 0]\n","\n","        return edges, orient_map\n","\n","    def _extract_template_edges_and_orientation(self, template_image):\n","        \"\"\"\n","        Templateìš©: Canny(30,100) + Skeleton (1px)\n","        \"\"\"\n","\n","        if len(template_image.shape) == 3:\n","            gray_img = cv2.cvtColor(template_image, cv2.COLOR_BGR2GRAY)\n","        else:\n","            gray_img = template_image\n","\n","        blurred = cv2.bilateralFilter(gray_img, d=5, sigmaColor=30, sigmaSpace=30)\n","        edges = cv2.Canny(blurred, 30, 100, L2gradient=True)\n","\n","        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(edges, connectivity=8)\n","        clean_edges = np.zeros_like(edges)\n","        for i in range(1, num_labels):\n","            if stats[i, cv2.CC_STAT_AREA] >= 10:\n","                clean_edges[labels == i] = 255\n","\n","        skeleton = np.zeros(clean_edges.shape, np.uint8)\n","        img_temp = clean_edges.copy()\n","        element = cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3))\n","\n","        while True:\n","            eroded = cv2.erode(img_temp, element)\n","            temp = cv2.dilate(eroded, element)\n","            temp = cv2.subtract(img_temp, temp)\n","            skeleton = cv2.bitwise_or(skeleton, temp)\n","            img_temp = eroded.copy()\n","            if cv2.countNonZero(img_temp) == 0:\n","                break\n","\n","        edges = skeleton\n","\n","        gx = cv2.Sobel(gray_img, cv2.CV_32F, 1, 0, ksize=3)\n","        gy = cv2.Sobel(gray_img, cv2.CV_32F, 0, 1, ksize=3)\n","        grad_angle = np.rad2deg(np.arctan2(gy, gx))\n","        grad_angle[grad_angle < 0] += 180.0\n","\n","        orient_map = np.full(grad_angle.shape, -1, dtype=np.float32)\n","        orient_map[edges > 0] = grad_angle[edges > 0]\n","\n","        return edges, orient_map\n","\n","    def _build_truncated_directional_distance_maps(self, edges, orient_map):\n","        h, w = edges.shape\n","        dist_maps = []\n","        for b in range(self.num_ori_bins):\n","            ang_min = b * self.ori_bin_angle\n","            ang_max = (b + 1) * self.ori_bin_angle\n","\n","            mask = np.zeros((h, w), dtype=np.uint8)\n","            bin_mask = (orient_map >= ang_min) & (orient_map < ang_max)\n","            mask[bin_mask] = 1\n","\n","            inv_mask = 1 - mask\n","            dist = distance_transform_edt(inv_mask)\n","\n","            # (ìµœì í™”) Truncation ë¯¸ë¦¬ ì ìš©\n","            dist = np.minimum(dist, self.truncation_dist).astype(np.float32)\n","            dist_maps.append(dist)\n","\n","        return dist_maps\n","\n","    def _rotate_template(self, image, angle):\n","        if angle == 0: return image.copy()\n","        (h, w) = image.shape[:2]\n","        (cX, cY) = (w // 2, h // 2)\n","        M = cv2.getRotationMatrix2D((cX, cY), angle, 1.0)\n","        cos, sin = np.abs(M[0, 0]), np.abs(M[0, 1])\n","        nW = int((h * sin) + (w * cos))\n","        nH = int((h * cos) + (w * sin))\n","        M[0, 2] += (nW / 2) - cX\n","        M[1, 2] += (nH / 2) - cY\n","        return cv2.warpAffine(image, M, (nW, nH), flags=cv2.INTER_NEAREST, borderValue=0)\n","\n","    def _get_template_masks_by_bin(self, template_gray):\n","        edges, grad_angle = self._extract_template_edges_and_orientation(template_gray)\n","\n","        valid = edges > 0\n","        bins = (grad_angle[valid] // self.ori_bin_angle).astype(np.int32)\n","        bins = np.clip(bins, 0, self.num_ori_bins - 1)\n","\n","        masks = []\n","        for b in range(self.num_ori_bins):\n","            mask = np.zeros_like(edges, dtype=np.float32)\n","            # bin_mapì„ ë‹¤ì‹œ ë§Œë“œëŠ” ëŒ€ì‹  ë°”ë¡œ ë§ˆìŠ¤í‚¹\n","            # í˜„ì¬ binì¸ í”½ì…€ë“¤ë§Œ 1.0\n","            mask_indices = (bins == b)\n","            # validí•œ í”½ì…€ ì¤‘ binì´ bì¸ ê²ƒë“¤ì˜ ì¢Œí‘œ\n","            y_idxs, x_idxs = np.where(valid)\n","            y_b = y_idxs[mask_indices]\n","            x_b = x_idxs[mask_indices]\n","            mask[y_b, x_b] = 1.0\n","            masks.append(mask)\n","\n","        return masks, edges\n","\n","    def _compute_score_map_fast(self, dist_maps, template_masks):\n","        total_cost_map = None\n","\n","        for b in range(self.num_ori_bins):\n","            t_mask = template_masks[b]\n","            if np.sum(t_mask) == 0:\n","                continue\n","\n","            # TM_CCORR: í…œí”Œë¦¿(1)ê³¼ ê²¹ì¹˜ëŠ” ì´ë¯¸ì§€ í”½ì…€(ê±°ë¦¬ê°’)ì„ ë‹¤ ë”í•¨\n","            # ìˆ˜ì‹: sum( dist_map(x+i, y+j) * template(i, j) )\n","            cost = cv2.matchTemplate(dist_maps[b], t_mask, cv2.TM_CCORR)\n","\n","            if total_cost_map is None:\n","                total_cost_map = cost\n","            else:\n","                total_cost_map += cost\n","\n","        return total_cost_map\n","\n","    def _get_edge_density_fast(self, integral_img, x, y, w, h):\n","        \"\"\"Integral Imageë¥¼ ì´ìš©í•œ O(1) Edge Density ê³„ì‚°\"\"\"\n","        # Integral imageëŠ” ì›ë³¸ë³´ë‹¤ í¬ê¸°ê°€ 1ì”© í¼\n","        # Sum = I[y2, x2] - I[y1, x2] - I[y2, x1] + I[y1, x1]\n","        y2 = min(y + h, integral_img.shape[0] - 1)\n","        x2 = min(x + w, integral_img.shape[1] - 1)\n","        y1 = max(y, 0)\n","        x1 = max(x, 0)\n","\n","        count = (integral_img[y2, x2]\n","                 - integral_img[y1, x2]\n","                 - integral_img[y2, x1]\n","                 + integral_img[y1, x1])\n","        return count\n","\n","    def _process_single_scale_and_angle(self, scale, angle, template_gray_orig, orig_w, orig_h):\n","        # --- 1. Coarse ë‹¨ê³„ (ê³ ì† í•„í„°ë§) ---\n","        c_w = int(orig_w * scale * self.coarse_scale)\n","        c_h = int(orig_h * scale * self.coarse_scale)\n","\n","        # Scene(Coarse) í¬ê¸°ë³´ë‹¤ í…œí”Œë¦¿ì´ í¬ë©´ ì¦‰ì‹œ ì¤‘ë‹¨\n","        scene_h_coarse, scene_w_coarse = self.dir_dist_maps_coarse[0].shape\n","\n","        if c_w >= scene_w_coarse or c_h >= scene_h_coarse: return None\n","        if c_w < 5 or c_h < 5: return None\n","\n","        t_coarse_resized = cv2.resize(template_gray_orig, (c_w, c_h))\n","        t_coarse_rot = self._rotate_template(t_coarse_resized, angle)\n","\n","        # íšŒì „ í›„ í¬ê¸°ê°€ Sceneë³´ë‹¤ í°ì§€ í•œ ë²ˆ ë” ì²´í¬\n","        tc_h, tc_w = t_coarse_rot.shape\n","        if tc_w > scene_w_coarse or tc_h > scene_h_coarse: return None\n","\n","        t_coarse_masks, t_coarse_edges = self._get_template_masks_by_bin(t_coarse_rot)\n","\n","        edge_pixel_count = np.sum(t_coarse_edges > 0)\n","        if edge_pixel_count == 0: return None\n","\n","        # (ìµœì í™”) ì „ì²´ ë§µì— ëŒ€í•´ í•œ ë²ˆì— ì ìˆ˜ ê³„ì‚°\n","        try:\n","            score_map_coarse = self._compute_score_map_fast(self.dir_dist_maps_coarse, t_coarse_masks)\n","        except cv2.error:\n","            return None\n","\n","        if score_map_coarse is None: return None\n","\n","        score_map_coarse /= edge_pixel_count\n","\n","        # ìµœì†Œ ë¹„ìš© ìœ„ì¹˜ ì°¾ê¸°\n","        min_val, _, min_loc, _ = cv2.minMaxLoc(score_map_coarse)\n","\n","        # Coarse Threshold (truncationì˜ ì ˆë°˜ë³´ë‹¤ í¬ë©´ ë²„ë¦¼)\n","        if min_val > self.truncation_dist * 0.6:\n","            return None\n","\n","        best_c_loc = min_loc  # (x, y)\n","\n","        # --- 2. Fine ë‹¨ê³„ (ì •ë°€ ê²€ì‚¬) ---\n","        # ì¢Œí‘œ ë³µì›\n","        orig_cx = int(best_c_loc[0] / self.coarse_scale)\n","        orig_cy = int(best_c_loc[1] / self.coarse_scale)\n","\n","        f_w = int(orig_w * scale)\n","        f_h = int(orig_h * scale)\n","\n","        scene_h_fine, scene_w_fine = self.dir_dist_maps_fine[0].shape\n","        if f_w >= scene_w_fine or f_h >= scene_h_fine: return None\n","        if f_w < 5 or f_h < 5: return None\n","\n","        t_fine_resized = cv2.resize(template_gray_orig, (f_w, f_h))\n","        t_fine_rot = self._rotate_template(t_fine_resized, angle)\n","\n","        tf_h, tf_w = t_fine_rot.shape\n","        if tf_w > scene_w_fine or tf_h > scene_h_fine: return None\n","\n","        t_fine_masks, t_fine_edges = self._get_template_masks_by_bin(t_fine_rot)\n","\n","        fine_edge_count = np.sum(t_fine_edges > 0)\n","        if fine_edge_count == 0: return None\n","\n","        # ROI ì„¤ì •\n","        margin = 20\n","        start_x = max(0, orig_cx - margin)\n","        start_y = max(0, orig_cy - margin)\n","        end_x = min(self.dir_dist_maps_fine[0].shape[1], orig_cx + f_w + margin)\n","        end_y = min(self.dir_dist_maps_fine[0].shape[0], orig_cy + f_h + margin)\n","\n","        roi_w = end_x - start_x\n","        roi_h = end_y - start_y\n","\n","        # ROIê°€ í…œí”Œë¦¿ë³´ë‹¤ ì‘ìœ¼ë©´ ë§¤ì¹­ ë¶ˆê°€\n","        if roi_w < tf_w or roi_h < tf_h: return None\n","\n","        # ROI í¬ë¡­ëœ Distance Maps\n","        roi_dist_maps = [d[start_y:end_y, start_x:end_x] for d in self.dir_dist_maps_fine]\n","\n","        # ROI ë‚´ì—ì„œ ë§¤ì¹­\n","        try:\n","            score_map_fine = self._compute_score_map_fast(roi_dist_maps, t_fine_masks)\n","        except cv2.error:\n","            return None\n","\n","        if score_map_fine is None: return None\n","\n","        score_map_fine /= fine_edge_count\n","\n","        # ROI ë‚´ ìµœì†Œê°’\n","        min_dist, _, min_loc_roi, _ = cv2.minMaxLoc(score_map_fine)\n","\n","        # ì „ì²´ ì¢Œí‘œê³„ë¡œ ë³€í™˜\n","        final_x = start_x + min_loc_roi[0]\n","        final_y = start_y + min_loc_roi[1]\n","\n","        # Edge Density Penalty (O(1) ì¡°íšŒ)\n","        scene_edge_cnt = self._get_edge_density_fast(\n","            self.integral_edges_fine, final_x, final_y, tf_w, tf_h\n","        )\n","        ratio = scene_edge_cnt / fine_edge_count\n","        penalty = 1.0\n","        if ratio > 6.0: # max_ratio\n","            penalty = ratio / 6.0\n","\n","        final_dist = min_dist * penalty\n","\n","        # Score ë³€í™˜ (0~1)\n","        final_score = max(0, 1.0 - (final_dist / self.truncation_dist))\n","\n","        return {\n","            'scale': round(scale, 2),\n","            'angle': angle,\n","            'score': round(final_score, 4),\n","            'chamfer_distance': round(final_dist, 4),\n","            'location': (final_x, final_y),\n","            'template_size': (f_w, f_h)\n","        }\n","\n","    def match(self, template_path, label, scale_range=(0.7, 1.3), scale_step=0.1, rotation_step=15, **kwargs):\n","        # í…œí”Œë¦¿ ë¡œë“œ í™•ì¸\n","        template_gray_orig = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n","        if template_gray_orig is None:\n","            print(f\"Error: Cannot read template {template_path}\")\n","            return {'label': label, 'best_score': 0, 'top_results': []}\n","\n","        orig_h, orig_w = template_gray_orig.shape\n","\n","        scales = np.arange(scale_range[0], scale_range[1] + scale_step / 2, scale_step)\n","        angles = np.arange(0, 360, rotation_step)\n","\n","        # ë³‘ë ¬ ì²˜ë¦¬\n","        results = Parallel(n_jobs=-1)(\n","            delayed(self._process_single_scale_and_angle)(scale, angle, template_gray_orig, orig_w, orig_h)\n","            for scale in scales\n","            for angle in angles\n","        )\n","\n","        valid_results = [r for r in results if r is not None]\n","        top_results = sorted(valid_results, key=lambda x: x['score'], reverse=True)[:3]\n","\n","        if not top_results:\n","            return {'label': label, 'best_score': 0, 'best_scale': 1.0, 'best_angle': 0, 'best_location': (0,0), 'top_results': []}\n","\n","        best_res = top_results[0]\n","        print(f\"   --> Best: Scale {best_res['scale']}x | Angle {best_res['angle']}Â° | Score {best_res['score']:.4f}\")\n","\n","        return {\n","            'label': label,\n","            'best_scale': best_res['scale'],\n","            'best_angle': best_res['angle'],\n","            'best_score': best_res['score'],\n","            'best_location': best_res['location'],\n","            'best_template_size': best_res['template_size'],\n","            'top_results': top_results\n","        }"],"metadata":{"id":"upQSHxmooofe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### HSV í•„í„°ë§ í—¬í¼ í•¨ìˆ˜"],"metadata":{"id":"Ny1C65qahd6j"}},{"cell_type":"code","source":["def find_optimal_k(data, max_k=8, threshold=0.15):\n","    n_samples = data.shape[0]\n","    if n_samples < max_k: return max(1, n_samples)\n","\n","    prev_compactness = float('inf')\n","    best_k = 1\n","\n","    for k in range(1, max_k + 1):\n","        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n","        compactness, _, _ = cv2.kmeans(data, k, None, criteria, 3, cv2.KMEANS_RANDOM_CENTERS)\n","\n","        if k == 1:\n","            prev_compactness = compactness\n","            continue\n","\n","        improvement = (prev_compactness - compactness) / prev_compactness\n","        if improvement < threshold:\n","            best_k = k - 1\n","            break\n","        best_k = k\n","        prev_compactness = compactness\n","\n","    return best_k\n","\n","def get_hsv_ranges(template_path,\n","                   auto_k=True, k=5,\n","                   margin_h=10, margin_s=30, margin_v=30,\n","                   min_valid_pixels=50):\n","\n","    img_bgr = cv2.imread(template_path)\n","    if img_bgr is None:\n","        print(f\"ì˜¤ë¥˜: {template_path} íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n","        return []\n","\n","    # --- 1. GrabCut: ë°°ê²½(í°ìƒ‰, ë°•ìŠ¤ ë“±)ì„ ë‚ ë¦¬ê³  ë¬¼ì²´ë§Œ ë‚¨ê¹€ ---\n","    mask = np.zeros(img_bgr.shape[:2], np.uint8)\n","    bgdModel = np.zeros((1, 65), np.float64)\n","    fgdModel = np.zeros((1, 65), np.float64)\n","\n","    h, w = img_bgr.shape[:2]\n","    rect = (1, 1, w-2, h-2)\n","\n","    # GrabCut ì‹¤í–‰ (ë°˜ë³µ 5íšŒ)\n","    try:\n","        cv2.grabCut(img_bgr, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n","    except Exception as e:\n","        print(f\"GrabCut ì‹¤íŒ¨: {e}\")\n","        return []\n","\n","    # 0(ë°°ê²½), 2(ë°°ê²½ì¶”ì •) -> 0 / 1(ì „ê²½), 3(ì „ê²½ì¶”ì •) -> 1\n","    mask_final = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n","\n","    # ë¬¼ì²´ í”½ì…€ ê°œìˆ˜ í™•ì¸\n","    if np.count_nonzero(mask_final) < min_valid_pixels:\n","        print(\"GrabCut ê²°ê³¼ ë¬¼ì²´ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n","        return []\n","\n","    # --- 2. ë¬¼ì²´ ì˜ì—­ì˜ HSV í”½ì…€ë§Œ ì¶”ì¶œ ---\n","    img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n","\n","    # ë§ˆìŠ¤í¬ê°€ 1ì¸ ë¶€ë¶„(ë¬¼ì²´)ì˜ í”½ì…€ë§Œ ê°€ì ¸ì˜´\n","    valid_data = img_hsv[mask_final == 1].astype(np.float32)\n","\n","    s_median = np.median(valid_data[:, 1])\n","    if s_median < 8:\n","        print(\"Template grayscale -> skip HSV\")\n","        return []\n","\n","    # --- 3. K-Means êµ°ì§‘í™” ë° ë²”ìœ„ ì‚°ì¶œ ---\n","    final_k = k\n","    if auto_k:\n","        sample_data = valid_data\n","        if len(valid_data) > 1000:\n","            indices = np.random.choice(len(valid_data), 1000, replace=False)\n","            sample_data = valid_data[indices]\n","        final_k = find_optimal_k(sample_data, max_k=8)\n","\n","    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n","    _, labels, centers = cv2.kmeans(valid_data, final_k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n","\n","    ranges = []\n","\n","    for i in range(final_k):\n","        # í˜„ì¬ ê·¸ë£¹ì˜ í”½ì…€ë“¤\n","        cluster_pixels = valid_data[labels.flatten() == i]\n","\n","        if len(cluster_pixels) < min_valid_pixels // final_k:\n","            continue\n","\n","        h_vals, s_vals, v_vals = cluster_pixels[:, 0], cluster_pixels[:, 1], cluster_pixels[:, 2]\n","\n","        # S, V ë²”ìœ„ ê³„ì‚°\n","        s_min = max(0, np.percentile(s_vals, 5) - margin_s)\n","        s_max = min(255, np.percentile(s_vals, 95) + margin_s)\n","        v_min = max(0, np.percentile(v_vals, 5) - margin_v)\n","        v_max = min(255, np.percentile(v_vals, 95) + margin_v)\n","\n","        # Hue Wrap-around ì²˜ë¦¬ (ë¹¨ê°„ìƒ‰ 0/179 ê²½ê³„ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´)\n","        h_shifted = (h_vals + 90) % 180\n","        h_start_s, h_end_s = np.percentile(h_shifted, 5), np.percentile(h_shifted, 95)\n","        h_start_s -= margin_h\n","        h_end_s += margin_h\n","\n","        h_start = (h_start_s - 90) % 180\n","        h_end = (h_end_s - 90) % 180\n","\n","        # ê²½ê³„ì„  ì¹¨ë²” ì²´í¬\n","        if h_start_s < 0 or h_end_s > 179 or h_start > h_end:\n","            # ë²”ìœ„ê°€ ëŠì–´ì§„ ê²½ìš° -> ë‘ ê°œë¡œ ë¶„í• \n","            ranges.append(((int(h_start), int(s_min), int(v_min)), (179, int(s_max), int(v_max))))\n","            ranges.append(((0, int(s_min), int(v_min)), (int(h_end), int(s_max), int(v_max))))\n","        else:\n","            # ì¼ë°˜ì ì¸ ê²½ìš° -> í•˜ë‚˜ë¡œ ì¶”ê°€\n","            ranges.append(((int(h_start), int(s_min), int(v_min)), (int(h_end), int(s_max), int(v_max))))\n","\n","    return ranges\n","\n","def is_scene_grayscale(scene_bgr, s_thresh=12, gray_ratio=0.95):\n","    \"\"\"\n","    sceneì´ ëŒ€ë¶€ë¶„ ë¬´ì±„ìƒ‰ì´ë©´ True\n","    - HSVì—ì„œ S(ì±„ë„)ê°€ ë§¤ìš° ë‚®ì€ í”½ì…€ ë¹„ìœ¨ì´ gray_ratio ì´ìƒì´ë©´ í‘ë°±/ë¬´ì±„ìƒ‰ìœ¼ë¡œ íŒë‹¨\n","    \"\"\"\n","    hsv = cv2.cvtColor(scene_bgr, cv2.COLOR_BGR2HSV)\n","    s = hsv[:, :, 1]\n","    ratio = np.mean(s < s_thresh)\n","    return ratio >= gray_ratio\n","\n","def create_color_mask(scene_path, template_path):\n","    scene_bgr = cv2.imread(scene_path)\n","    if scene_bgr is None:\n","        raise FileNotFoundError(f\"Scene ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {scene_path}\")\n","\n","    if is_scene_grayscale(scene_bgr):\n","        return None\n","\n","    hsv_scene = cv2.cvtColor(scene_bgr, cv2.COLOR_BGR2HSV)\n","\n","    ranges = get_hsv_ranges(template_path, auto_k=True)\n","\n","    if not ranges:\n","        return None\n","\n","    final_mask = np.zeros(hsv_scene.shape[:2], dtype=np.uint8)\n","    for lower, upper in ranges:\n","        mask = cv2.inRange(hsv_scene, np.array(lower, dtype=np.uint8), np.array(upper, dtype=np.uint8))\n","        final_mask = cv2.bitwise_or(final_mask, mask)\n","\n","    return final_mask"],"metadata":{"id":"65PQtA1GB_V4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_VHrf79G6r3i"},"source":["### Color GHT Matching"]},{"cell_type":"code","source":["class ColorGHTMatcher:\n","    def __init__(self, scene_path: str):\n","        self.scene_bgr = cv2.imread(scene_path)\n","        self.scene = cv2.cvtColor(self.scene_bgr, cv2.COLOR_BGR2GRAY)\n","\n","        # ë…¸ì´ì¦ˆ ì œê±°\n","        self.scene = cv2.bilateralFilter(self.scene, 5, 50, 50)\n","\n","        # 1. Fine Scale (ì›ë³¸)\n","        self.grad_fine, self.orient_fine, self.mask_fine = self._compute_gradients(self.scene)\n","\n","        # 2. Coarse Scale (1/2 ì¶•ì†Œ)\n","        self.coarse_scale = 0.5\n","        scene_small = cv2.resize(self.scene, None, fx=self.coarse_scale, fy=self.coarse_scale)\n","        self.grad_coarse, self.orient_coarse, self.mask_coarse = self._compute_gradients(scene_small)\n","\n","    def _compute_gradients(self, img):\n","        \"\"\"Sobel Gradient, Orientation, Edge Mask ê³„ì‚°\"\"\"\n","        dx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\n","        dy = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)\n","\n","        magnitude = cv2.magnitude(dx, dy)\n","        orientation = np.degrees(np.arctan2(dy, dx)).astype(int) % 360\n","\n","        # ì—£ì§€ ë§ˆìŠ¤í¬ (ë„ˆë¬´ ì•½í•œ ì—£ì§€ëŠ” íˆ¬í‘œì— ì°¸ì—¬ ì•ˆ ì‹œí‚´)\n","        mask = magnitude > 30\n","        return magnitude, orientation, mask\n","\n","    def _build_r_table(self, template):\n","        \"\"\"Templateì˜ ê¸°ë³¸ R-Table ìƒì„± (0ë„, 1.0ë°°)\"\"\"\n","        dx = cv2.Sobel(template, cv2.CV_64F, 1, 0, ksize=3)\n","        dy = cv2.Sobel(template, cv2.CV_64F, 0, 1, ksize=3)\n","\n","        magnitude = cv2.magnitude(dx, dy)\n","        orientation = np.degrees(np.arctan2(dy, dx)).astype(int) % 360\n","        edge_mask = magnitude > 40\n","\n","        h, w = template.shape\n","        xc, yc = w // 2, h // 2\n","\n","        y_idxs, x_idxs = np.where(edge_mask)\n","        mags = magnitude[edge_mask]\n","        ors = orientation[edge_mask]\n","\n","        r_table = {}\n","        for x, y, mag, angle in zip(x_idxs, y_idxs, mags, ors):\n","            if angle not in r_table: r_table[angle] = []\n","            # (dx, dy, mag) ì €ì¥\n","            r_table[angle].append((xc - x, yc - y, mag))\n","\n","        return r_table, (w, h)\n","\n","    def _get_rotated_r_table(self, r_table, angle, scale):\n","        \"\"\"\n","        R-tableì„ ë¯¸ë¦¬ íšŒì „ ë° ìŠ¤ì¼€ì¼ë§í•˜ì—¬ ìƒˆë¡œìš´ í…Œì´ë¸” ìƒì„±\n","        -> Inner Loopì—ì„œ sin/cos ì—°ì‚° ì œê±° -> ì†ë„ í–¥ìƒ\n","        \"\"\"\n","        theta_rad = np.radians(angle)\n","        cos_t = np.cos(theta_rad)\n","        sin_t = np.sin(theta_rad)\n","\n","        rotated_r_table = {}\n","\n","        for t_angle, vectors in r_table.items():\n","            # í…œí”Œë¦¿ì´ íšŒì „í•˜ë©´ ì—£ì§€ ê°ë„ë„ íšŒì „í•¨\n","            # Sceneì—ì„œ ì°¾ì„ ë•ŒëŠ” (ê¸°ì¡´ ê°ë„ + íšŒì „ ê°ë„)ë¥¼ í‚¤ë¡œ ì‚¬ìš©\n","            scene_query_angle = int(t_angle + angle) % 360\n","\n","            new_vectors = []\n","            for dx, dy, mag in vectors:\n","                # 1. ë²¡í„° íšŒì „\n","                rdx = dx * cos_t - dy * sin_t\n","                rdy = dx * sin_t + dy * cos_t\n","\n","                # 2. ìŠ¤ì¼€ì¼ ì ìš©\n","                final_dx = int(rdx * scale)\n","                final_dy = int(rdy * scale)\n","\n","                new_vectors.append((final_dx, final_dy, mag))\n","\n","            if scene_query_angle not in rotated_r_table:\n","                rotated_r_table[scene_query_angle] = []\n","            rotated_r_table[scene_query_angle].extend(new_vectors)\n","\n","        return rotated_r_table\n","\n","    def _vote(self, rotated_r_table, scene_grad, scene_orient, scene_mask):\n","        h, w = scene_grad.shape\n","        accumulator = np.zeros((h, w), dtype=np.float32)\n","\n","        # Scene ì—£ì§€ í”½ì…€ ì¶”ì¶œ\n","        y_idxs, x_idxs = np.where(scene_mask)\n","        s_mags = scene_grad[scene_mask]\n","        s_ors = scene_orient[scene_mask]\n","\n","        # íˆ¬í‘œ\n","        for i, (sy, sx) in enumerate(zip(y_idxs, x_idxs)):\n","            scene_angle = s_ors[i]\n","\n","            # ë¯¸ë¦¬ ë§Œë“¤ì–´ë‘” Rotated Table ì¡°íšŒ\n","            if scene_angle in rotated_r_table:\n","                for rdx, rdy, rmag in rotated_r_table[scene_angle]:\n","                    # ì´ë¯¸ íšŒì „/ìŠ¤ì¼€ì¼ë§ ëœ ë²¡í„°ë¥¼ ë”í•˜ê¸°ë§Œ í•¨\n","                    xc = sx + rdx\n","                    yc = sy + rdy\n","\n","                    if 0 <= xc < w and 0 <= yc < h:\n","                        # Weighted Voting\n","                        accumulator[yc, xc] += (s_mags[i] * rmag)\n","\n","        # Smoothing\n","        accumulator = cv2.GaussianBlur(accumulator, (9, 9), 2.0)\n","        return accumulator\n","\n","    def _process_coarse_to_fine(self, scale, angle, r_table, t_w, t_h, color_mask=None):\n","        # --- 1. Coarse Search (1/2 Scale) ---\n","        coarse_eff_scale = scale * self.coarse_scale\n","\n","        # Coarse ë ˆë²¨ ë§ˆìŠ¤í¬ ì ìš©\n","        final_mask_coarse = self.mask_coarse\n","        if color_mask is not None:\n","            mask_small = cv2.resize(color_mask, None, fx=self.coarse_scale, fy=self.coarse_scale, interpolation=cv2.INTER_NEAREST)\n","            # \"ì—£ì§€ë„ ìˆê³ (True) AND ìƒ‰ê¹”ë„ ë§ëŠ”(>0) ê³³\"ë§Œ ë‚¨ê¹€\n","            final_mask_coarse = self.mask_coarse & (mask_small > 0)\n","\n","        # ì—£ì§€ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ìŠ¤í‚µ (ì†ë„ í–¥ìƒ)\n","        if not np.any(final_mask_coarse):\n","            return None\n","\n","        coarse_r_table = self._get_rotated_r_table(r_table, angle, coarse_eff_scale)\n","\n","        # íˆ¬í‘œ í•¨ìˆ˜ì— 'í•©ì³ì§„ ë§ˆìŠ¤í¬'ë¥¼ ì „ë‹¬\n","        acc_coarse = self._vote(\n","            coarse_r_table,\n","            self.grad_coarse, self.orient_coarse, final_mask_coarse\n","        )\n","\n","        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(acc_coarse)\n","        if max_val < 500: return None\n","\n","        # Coarse ìœ„ì¹˜ -> Fine ìœ„ì¹˜ ë³€í™˜\n","        center_x_coarse, center_y_coarse = max_loc\n","        orig_cx = int(center_x_coarse / self.coarse_scale)\n","        orig_cy = int(center_y_coarse / self.coarse_scale)\n","\n","        # --- 2. Fine Search (ROI Only) ---\n","        margin = 30\n","        fine_h, fine_w = self.grad_fine.shape\n","\n","        start_x = max(0, orig_cx - margin - int(t_w*scale/2))\n","        start_y = max(0, orig_cy - margin - int(t_h*scale/2))\n","        end_x = min(fine_w, orig_cx + margin + int(t_w*scale/2))\n","        end_y = min(fine_h, orig_cy + margin + int(t_h*scale/2))\n","\n","        if end_x <= start_x or end_y <= start_y: return None\n","\n","        # ROI ì˜ë¼ë‚´ê¸°\n","        grad_roi = self.grad_fine[start_y:end_y, start_x:end_x]\n","        orient_roi = self.orient_fine[start_y:end_y, start_x:end_x]\n","        mask_roi = self.mask_fine[start_y:end_y, start_x:end_x]\n","\n","        # Fine ë ˆë²¨ ë§ˆìŠ¤í¬ ì ìš© (ROI ë¶€ë¶„ë§Œ ì˜ë¼ì„œ)\n","        if color_mask is not None:\n","            color_mask_roi = color_mask[start_y:end_y, start_x:end_x]\n","            mask_roi = mask_roi & (color_mask_roi > 0)\n","\n","        if not np.any(mask_roi): return None\n","\n","        fine_r_table = self._get_rotated_r_table(r_table, angle, scale)\n","        acc_fine_roi = self._vote(fine_r_table, grad_roi, orient_roi, mask_roi)\n","\n","        f_min, f_max, f_loc_min, f_loc_max = cv2.minMaxLoc(acc_fine_roi)\n","\n","        final_cx = start_x + f_loc_max[0]\n","        final_cy = start_y + f_loc_max[1]\n","\n","        return {\n","            'scale': scale,\n","            'angle': angle,\n","            'votes': f_max,\n","            'location': (final_cx, final_cy),\n","            'box': (int(final_cx - t_w*scale//2), int(final_cy - t_h*scale//2),\n","                    int(t_w*scale), int(t_h*scale))\n","        }\n","\n","    def match(self, template_path, label, scale_range=(0.8, 1.4), scale_step=0.1, rotation_step=15, color_mask=None):\n","        template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n","        r_table, (t_w, t_h) = self._build_r_table(template)\n","\n","        print(f\"\\n{'='*90}\")\n","        print(f\"   Optimized GHT (Rotated Table + Coarse-to-Fine): {label}\")\n","        print(f\"   Scale: {scale_range} | Rot Step: {rotation_step}Â°\")\n","\n","        scales = np.arange(scale_range[0], scale_range[1] + 1e-5, scale_step)\n","        angles = np.arange(0, 360, rotation_step)\n","\n","        results = Parallel(n_jobs=-1)(\n","            delayed(self._process_coarse_to_fine)(scale, angle, r_table, t_w, t_h, color_mask)\n","            for scale in scales\n","            for angle in angles\n","        )\n","\n","        valid_results = [r for r in results if r is not None]\n","        valid_results.sort(key=lambda x: x['votes'], reverse=True)\n","\n","        top_results = valid_results[:3]\n","\n","        if not top_results:\n","             print(\"   âŒ No match found.\")\n","             return {'label': label, 'best_score': 0, 'best_scale': 1.0, 'best_location': (0,0), 'top_results': []}\n","\n","        best_res = top_results[0]\n","        norm_score = min(1.0, best_res['votes'] / 100000.0)\n","\n","        print(f\"\\nìƒìœ„ ê²°ê³¼:\")\n","        for i, res in enumerate(top_results, 1):\n","            print(f\"  {i}. Scale {res['scale']:.2f}x | Angle {res['angle']}Â°| Votes {best_res['votes']:.0f}\")\n","\n","        center_x, center_y = best_res['location']\n","        bw, bh = best_res['box'][2], best_res['box'][3]\n","\n","        return {\n","            'label': label,\n","            'best_scale': best_res['scale'],\n","            'best_angle': best_res['angle'],\n","            'best_score': norm_score,\n","            'best_votes': best_res['votes'],\n","            'best_location': (int(center_x - bw/2), int(center_y - bh/2)),\n","            'best_template_size': (bw, bh),\n","            'top_results': valid_results[:3]\n","        }"],"metadata":{"id":"Mb6_EHy8_w0r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Wrapper\n","\n","ì´ë¯¸ì§€ íƒ€ì…ì— ë”°ë¼ ìë™ìœ¼ë¡œ ì ì ˆí•œ ë§¤ì²˜(Matcher)ë¥¼ ì„ íƒí•˜ëŠ” Wrapper Class"],"metadata":{"id":"vZpkN7IfoYNA"}},{"cell_type":"code","source":["class MultiMatcher:\n","    \"\"\"\n","    ì´ë¯¸ì§€ íƒ€ì…(ì»¬ëŸ¬/í‘ë°±)ì„ ê°ì§€í•˜ì—¬ ì ì ˆí•œ Matcherë¡œ ì—°ê²°í•˜ëŠ” Wrapper í´ë˜ìŠ¤\n","    \"\"\"\n","    is_wrapper = True\n","\n","    def __init__(self, scene_path: str, **kwargs):\n","        self.scene_path = scene_path\n","\n","        test_img = cv2.imread(scene_path, cv2.IMREAD_COLOR)\n","\n","        if test_img is None:\n","            raise ValueError(f\"Cannot load scene image: {scene_path}\")\n","\n","        is_grayscale = False\n","\n","        if len(test_img.shape) == 2 or (len(test_img.shape) == 3 and test_img.shape[2] == 1):\n","            is_grayscale = True\n","        else:\n","            hsv = cv2.cvtColor(test_img, cv2.COLOR_BGR2HSV)\n","            saturation = hsv[:, :, 1]\n","            mean_saturation = np.mean(saturation)\n","\n","            if mean_saturation < 4.0:\n","                is_grayscale = True\n","                print(f\"[Check] 3-channel image but Low Saturation (Mean S={mean_saturation:.2f}). Treating as Grayscale.\")\n","\n","        if is_grayscale:\n","            print(f\"ğŸ–¤ [Info] Grayscale Scene detected ({scene_path}). Using Grayscale Matcher.\")\n","            self.matcher = GrayscaleChamferMatcher(scene_path, **kwargs)\n","        else:\n","            print(f\"ğŸ¨ [Info] Color Scene detected ({scene_path}). Using Original Color Matcher.\")\n","            self.matcher = ColorGHTMatcher(scene_path)\n","\n","    def match(self, *args, **kwargs):\n","        return self.matcher.match(*args, **kwargs)\n","\n","    def __getattr__(self, name):\n","        return getattr(self.matcher, name)"],"metadata":{"id":"0fdpGhn0pYhb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K5oC0DcJcJ5w"},"source":["## Detection"]},{"cell_type":"code","source":["def find_all_objects(scene_path: str,\n","                     template_paths: dict,\n","                     method: str = 'multi',\n","                     scale_range=(0.8, 1.4),\n","                     scale_step=0.1,\n","                     **kwargs):\n","\n","    if method == 'multi':\n","        matcher = MultiMatcher(scene_path, **kwargs)\n","        match_func = matcher.match\n","    else:\n","        raise ValueError(f\"Unknown method: {method}\")\n","\n","    all_detections = []\n","\n","    print(f\"Finding All Objects using {method.upper()} method\")\n","    print(f\"{'='*90}\\n\")\n","\n","    for label, template_path in template_paths.items():\n","        print(f\"\\nğŸ” Searching for: {label}\")\n","\n","        result = match_func(\n","            template_path=template_path,\n","            label=label,\n","            scale_range=scale_range,\n","            scale_step=scale_step\n","        )\n","\n","        all_detections.append(result)\n","\n","        score = result['best_score']\n","        scale = result['best_scale']\n","        angle = result.get('best_angle')\n","\n","        if angle is not None:\n","            print(f\"   âœ“ Best score: {score:.4f} at scale {scale:.2f}x, angle {angle}Â°\")\n","        else:\n","            print(f\"   âœ“ Best score: {score:.4f} at scale {scale:.2f}x\")\n","\n","    return all_detections"],"metadata":{"id":"9mCPoWhyiBdF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dzYd28NxARSL"},"source":["## Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ATO-3TX2gHnw"},"outputs":[],"source":["def visualize_all_objects(scene_path: str,\n","                         detections: list,\n","                         output_path: str,\n","                         method_name: str = \"Multi-Object Detection\",\n","                         show_scores: bool = True):\n","    # Scene ë¡œë“œ\n","    scene = cv2.imread(scene_path)\n","    if scene is None:\n","        raise ValueError(f\"Cannot load scene image: {scene_path}\")\n","\n","    scene_h, scene_w = scene.shape[:2]\n","\n","    # Scene íŒŒì¼ëª… ì¶”ì¶œ (íŒŒì¼ëª…ì— í¬í•¨ì‹œí‚¬ ìš©ë„)\n","    scene_name = os.path.splitext(os.path.basename(scene_path))[0]\n","\n","    # ìƒ‰ìƒ íŒ”ë ˆíŠ¸\n","    colors = [\n","        (0, 255, 0),      # Green\n","        (255, 0, 0),      # Blue\n","        (0, 165, 255),    # Orange\n","        (255, 0, 255),    # Magenta\n","        (0, 255, 255),    # Yellow\n","        (255, 255, 0),    # Cyan\n","        (128, 0, 128),    # Purple\n","        (255, 128, 0),    # Sky Blue\n","    ]\n","\n","    # ê° ê°ì§€ ê²°ê³¼ ê·¸ë¦¬ê¸°\n","    for idx, result in enumerate(detections):\n","        label = result['label']\n","        location = result['best_location']\n","        template_size = result['best_template_size']\n","        score = result['best_score']\n","        scale = result['best_scale']\n","        angle = result.get('best_angle', 0) # angle ì •ë³´ê°€ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì²˜ë¦¬\n","\n","        x, y = int(location[0]), int(location[1])\n","        w, h = int(template_size[0]), int(template_size[1])\n","\n","        color = colors[idx % len(colors)]\n","\n","        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°\n","        if x >= 0 and y >= 0 and x + w <= scene_w and y + h <= scene_h:\n","            cv2.rectangle(scene, (x, y), (x + w, y + h), color, 2)\n","\n","            # ë¼ë²¨ í…ìŠ¤íŠ¸ ì¤€ë¹„\n","            if show_scores:\n","                angle_text = f\", {angle}Â°\" if angle != 0 else \"\"\n","                text = f\"{label} ({scale:.1f}x{angle_text}, {score:.2f})\"\n","            else:\n","                text = f\"{label}\"\n","\n","            # í…ìŠ¤íŠ¸ ë°°ê²½\n","            font = cv2.FONT_HERSHEY_SIMPLEX\n","            font_scale = 0.4\n","            thickness = 2\n","\n","            text_size = cv2.getTextSize(text, font, font_scale, thickness)[0]\n","\n","            # í…ìŠ¤íŠ¸ ìœ„ì¹˜\n","            text_x = x\n","            text_y = y - 5 if y - 5 > 15 else y + h + 15\n","\n","            # í…ìŠ¤íŠ¸ ë°°ê²½ ê·¸ë¦¬ê¸°\n","            cv2.rectangle(scene,\n","                         (text_x, text_y - text_size[1] - 4),\n","                         (text_x + text_size[0] + 4, text_y + 4),\n","                         color, -1)\n","\n","            # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°\n","            cv2.putText(scene, text, (text_x + 2, text_y),\n","                       font, font_scale, (255, 255, 255), thickness)\n","\n","    # ë©”ì„œë“œ ì œëª©\n","    title = f\"{method_name} - {len(detections)} objects detected - Scene: {scene_name}\"\n","    title_font_scale = 0.6\n","    title_thickness = 2\n","\n","    title_size = cv2.getTextSize(title, cv2.FONT_HERSHEY_SIMPLEX, title_font_scale, title_thickness)[0]\n","\n","    # ì œëª© ë°°ê²½\n","    cv2.rectangle(scene, (5, 5), (15 + title_size[0], 15 + title_size[1]), (0, 0, 0), -1)\n","    # ì œëª© í…ìŠ¤íŠ¸\n","    cv2.putText(scene, title, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, title_font_scale, (0, 255, 255), title_thickness)\n","\n","    # ê²°ê³¼ ì €ì¥\n","    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n","    cv2.imwrite(output_path, scene)\n","    print()\n","    print(f\"âœ“ Visualization saved: {output_path}\")\n","\n","    return scene"]},{"cell_type":"markdown","source":["## Evaluation"],"metadata":{"id":"Fd6B_oFNm-gx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"a4wlj8MheaQS"},"outputs":[],"source":["def auto_find_templates(scene_path, template_dir):\n","    \"\"\"\n","    Scene íŒŒì¼ ê²½ë¡œì™€ í…œí”Œë¦¿ ë””ë ‰í† ë¦¬ì—ì„œ ìë™ìœ¼ë¡œ í…œí”Œë¦¿ ì°¾ê¸°\n","    \"\"\"\n","    # Scene íŒŒì¼ëª… ì¶”ì¶œ\n","    scene_filename = os.path.basename(scene_path)\n","    scene_prefix = os.path.splitext(scene_filename)[0]\n","\n","    # í…œí”Œë¦¿ ë””ë ‰í† ë¦¬ì—ì„œ í•´ë‹¹ sceneì˜ í…œí”Œë¦¿ ì°¾ê¸°\n","    template_paths = {}\n","\n","    # íŒ¨í„´: scene_prefix-*.jpg\n","    pattern = os.path.join(template_dir, f'{scene_prefix}-*.*')\n","\n","    for filepath in glob.glob(pattern):\n","        filename = os.path.basename(filepath)\n","\n","        # í™•ì¥ìê°€ ì´ë¯¸ì§€ íŒŒì¼ì¸ì§€ í™•ì¸\n","        if not filename.lower().endswith(('.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG')):\n","            continue\n","\n","        # ë¼ë²¨ ì¶”ì¶œ\n","        name_without_ext = os.path.splitext(filename)[0]\n","        label = name_without_ext.replace(f'{scene_prefix}-', '', 1)\n","\n","        template_paths[label] = filepath\n","\n","    return template_paths"]},{"cell_type":"code","source":["def compare_all_methods(scene_path: str,\n","                       template_paths: dict,\n","                       output_dir: str,\n","                       scale_range=(0.5, 2.0),\n","                       scale_step=0.2,\n","                       methods=('multi',)):\n","    \"\"\"\n","    ì—¬ëŸ¬ ë°©ë²• ë¹„êµ\n","    (ìµœì¢…ì ìœ¼ë¡œ multi(Chamfer for Grayscale, GHT for Color) methodë§Œ ì´ìš©í•¨)\n","    \"\"\"\n","    scene_name = os.path.splitext(os.path.basename(scene_path))[0]\n","    all_results = {}\n","\n","    for method in methods:\n","        detections = find_all_objects(\n","            scene_path=scene_path,\n","            template_paths=template_paths,\n","            method=method,\n","            scale_range=scale_range,\n","            scale_step=scale_step\n","        )\n","\n","        all_results[method] = detections\n","\n","        output_path = os.path.join(output_dir, f\"{scene_name}_all_objects_{method}.png\")\n","        visualize_all_objects(\n","            scene_path=scene_path,\n","            detections=detections,\n","            output_path=output_path,\n","            method_name=f\"{method.upper()} Matching\"\n","        )\n","\n","    # methods ê°œìˆ˜ì— ë§ì¶° ë¹„êµ ì´ë¯¸ì§€ ìƒì„± (methodsê°€ 1ê°œë©´ ë¹„êµ ì´ë¯¸ì§€ë„ 1ê°œ í­)\n","    scene = cv2.imread(scene_path)\n","    scene_h, scene_w = scene.shape[:2]\n","\n","    comparison = np.zeros((scene_h, scene_w * len(methods), 3), dtype=np.uint8)\n","\n","    for col_idx, method in enumerate(methods):\n","        result_path = os.path.join(output_dir, f\"{scene_name}_all_objects_{method}.png\")\n","        result_img = cv2.imread(result_path)\n","        if result_img is None:\n","            continue\n","        comparison[:, col_idx*scene_w:(col_idx+1)*scene_w] = result_img\n","\n","    comparison_path = os.path.join(output_dir, f\"{scene_name}_comparison_all_methods.png\")\n","    cv2.imwrite(comparison_path, comparison)\n","\n","    return all_results"],"metadata":{"id":"ObsJOqbdm9vr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["possible_exts = [\"png\", \"PNG\", \"jpg\", \"JPG\", \"jpeg\", \"JPEG\"]\n","\n","def find_template_file(scene_id, template_dir, template_name):\n","    base = f\"{scene_id}-{template_name}\"\n","    for ext in possible_exts:\n","        fp = os.path.join(template_dir, f\"{base}.{ext}\")\n","        if os.path.exists(fp):\n","            return fp\n","    return None\n","\n","def get_template_radius(scene_id, template_dir, template_name):\n","    file_path = find_template_file(scene_id, template_dir, template_name)\n","    if file_path is None or (not os.path.exists(file_path)):\n","        print(f\"[ê²½ê³ ] í…œí”Œë¦¿ ì´ë¯¸ì§€ ì—†ìŒ: {scene_id}-{template_name} â†’ ê¸°ë³¸ ë°˜ì§€ë¦„ 40\")\n","        return 40\n","\n","    img = cv2.imread(file_path)\n","    if img is None:\n","        print(f\"[ê²½ê³ ] í…œí”Œë¦¿ ì½ê¸° ì‹¤íŒ¨: {file_path} â†’ ê¸°ë³¸ ë°˜ì§€ë¦„ 40\")\n","        return 40\n","\n","    h, w = img.shape[:2]\n","    radius = int(max(w, h) * 0.5)\n","    radius = min(radius, 120)\n","    return radius\n","\n","def calculate_iou(boxA, boxB):\n","    xA, yA, wA, hA = boxA\n","    xB, yB, wB, hB = boxB\n","    A = (xA, yA, xA + wA, yA + hA)\n","    B = (xB, yB, xB + wB, yB + hB)\n","\n","    x1 = max(A[0], B[0]); y1 = max(A[1], B[1])\n","    x2 = min(A[2], B[2]); y2 = min(A[3], B[3])\n","\n","    iw = max(0, x2 - x1)\n","    ih = max(0, y2 - y1)\n","    inter = iw * ih\n","\n","    areaA = wA * hA\n","    areaB = wB * hB\n","    denom = (areaA + areaB - inter)\n","    if denom <= 0:\n","        return 0.0\n","    return inter / denom"],"metadata":{"id":"17jYzPg7nCjV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def draw_dashed_circle(img, center, radius, color, thickness=2, dash_len=10):\n","    x, y = center\n","    for angle in range(0, 360, dash_len * 2):\n","        cv2.ellipse(img, (x, y), (radius, radius), 0, angle, angle + dash_len, color, thickness)\n","\n","def visualize_combined_results(scene_path: str,\n","                               detections: list,\n","                               df_scene_gt: pd.DataFrame,\n","                               output_path: str,\n","                               template_dir: str,\n","                               scene_id: str,\n","                               iou_threshold: float = 0.5):\n","    scene = cv2.imread(scene_path)\n","    if scene is None:\n","        raise ValueError(f\"Cannot load scene image: {scene_path}\")\n","\n","    scene_h, scene_w = scene.shape[:2]\n","\n","    COLOR_TP = (255, 0, 0)       # Blue\n","    COLOR_FP = (0, 0, 255)       # Red\n","    COLOR_FN = (100, 100, 100)   # Dark Gray\n","\n","    matched_gt_indices = set()\n","\n","\n","# 1. Detection ìˆœíšŒ ë° ë§¤ì¹­ í™•ì¸\n","    for det in detections:\n","        label = det['label']\n","        x, y = map(int, det['best_location'])\n","        w, h = map(int, det['best_template_size'])\n","\n","        # ì¤‘ì‹¬ì  ê³„ì‚°\n","        det_cx, det_cy = x + w / 2, y + h / 2\n","\n","        # í•´ë‹¹ ë¼ë²¨ì˜ GT í›„ë³´êµ° ì¶”ì¶œ\n","        gt_candidates = df_scene_gt[df_scene_gt['template'] == label]\n","\n","        is_correct = False\n","\n","        # GT í›„ë³´ë“¤ê³¼ ê±°ë¦¬ ë¹„êµ\n","        for idx, row in gt_candidates.iterrows():\n","            gt_x, gt_y = int(row['x']), int(row['y'])\n","            radius = get_template_radius(scene_id, template_dir, label)\n","\n","            # ê±°ë¦¬ ê³„ì‚°\n","            dist = ((det_cx - gt_x)**2 + (det_cy - gt_y)**2)**0.5\n","\n","            # ì •ë‹µ íŒë³„ (0.5R ì´ë‚´)\n","            if dist <= radius * 0.5:\n","                is_correct = True\n","                matched_gt_indices.add(idx)\n","\n","        if is_correct:\n","            # True Positive (Blue Box)\n","            cv2.rectangle(scene, (x, y), (x + w, y + h), COLOR_TP, 3)\n","            cv2.putText(scene, f\"{label}\", (x, y - 10),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, COLOR_TP, 2)\n","        else:\n","            # False Positive (Red Box w/ X mark)\n","            cv2.line(scene, (x, y), (x + w, y + h), COLOR_FP, 3)\n","            cv2.line(scene, (x + w, y), (x, y + h), COLOR_FP, 3)\n","            cv2.putText(scene, f\"{label}\", (x, y - 10),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, COLOR_FP, 2)\n","\n","    # 2. ë¯¸ê²€ì¶œ GT (False Negative) ìˆœíšŒ\n","    # matched_gt_indicesì— ì—†ëŠ” GTë§Œ íšŒìƒ‰ ì ì„ ìœ¼ë¡œ ê·¸ë¦¼\n","    for idx, row in df_scene_gt.iterrows():\n","        if idx not in matched_gt_indices:\n","            gt_x, gt_y = int(row['x']), int(row['y'])\n","            template_name = row['template']\n","            radius = get_template_radius(scene_id, template_dir, template_name)\n","\n","            draw_dashed_circle(scene, (gt_x, gt_y), radius, COLOR_FN, thickness=2, dash_len=10)\n","            cv2.putText(scene, f\"{template_name}\", (gt_x - radius, gt_y - radius - 10),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLOR_FN, 2)\n","\n","    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n","    cv2.imwrite(output_path, scene)\n","    print(f\"âœ“ Visualization saved: {output_path}\")\n","    return scene\n","\n","def parse_scene_gt(df_gt_all, scene_id):\n","    df_scene = df_gt_all[df_gt_all['scene'] == scene_id].copy()\n","    if df_scene.empty:\n","        return df_scene\n","\n","    split_coords = df_scene['px'].astype(str).str.split(',', expand=True)\n","    df_scene['x'] = split_coords[0].str.strip().astype(int)\n","    df_scene['y'] = split_coords[1].str.strip().astype(int)\n","    return df_scene\n","\n","def evaluate_one_scene(scene_path, template_dir, output_dir,\n","                       df_gt_all=None, df_scene_gt=None, scale_range=(0.7, 1.0), scale_step=0.1,\n","                       iou_threshold=0.5):\n","    scene_id = os.path.splitext(os.path.basename(scene_path))[0]\n","    scene_out_dir = os.path.join(output_dir, scene_id)\n","    os.makedirs(scene_out_dir, exist_ok=True)\n","\n","    # í…œí”Œë¦¿ ìë™ íƒìƒ‰\n","    template_paths = auto_find_templates(scene_path, template_dir)\n","    if not template_paths:\n","        print(f\"âš ï¸ [{scene_id}] í…œí”Œë¦¿ì´ ì—†ì–´ ìŠ¤í‚µí•©ë‹ˆë‹¤.\")\n","        return None\n","\n","    # íƒì§€ ì‹¤í–‰ (í˜„ì¬ ghtë§Œ)\n","    results = compare_all_methods(\n","        scene_path=scene_path,\n","        template_paths=template_paths,\n","        output_dir=scene_out_dir,\n","        scale_range=scale_range,\n","        scale_step=scale_step,\n","        methods=('multi',)\n","    )\n","\n","    detections = results['multi']  # list\n","\n","    # GT ì—†ìœ¼ë©´ íƒì§€ë§Œ ì €ì¥í•˜ê³  ì¢…ë£Œ\n","    if df_scene_gt is None or df_scene_gt.empty:\n","        print(f\"âš ï¸ [{scene_id}] GTê°€ ì—†ì–´ í‰ê°€ ìŠ¤í‚µ (íƒì§€ë§Œ ì €ì¥).\")\n","        return {\n","            'scene_id': scene_id,\n","            'n_templates': len(template_paths),\n","            'accuracy': None,\n","            'matched': '',\n","            'unmatched': '',\n","            'metrics_csv': None,\n","            '_correct_cnt': 0,\n","            '_total_cnt': 0\n","        }\n","\n","    df_scene = df_scene_gt\n","\n","    # Distance/IoU ê³„ì‚°\n","    distances = []\n","    ious = []\n","\n","    for det in detections:\n","        label = det['label']\n","        x_det, y_det = det['best_location']\n","        w_det, h_det = det['best_template_size']\n","\n","        cx_det = x_det + w_det / 2\n","        cy_det = y_det + h_det / 2\n","\n","        gt_entry = df_scene[df_scene['template'] == label]\n","        if gt_entry.empty:\n","            continue\n","\n","        cx_gt = int(gt_entry['x'].iloc[0])\n","        cy_gt = int(gt_entry['y'].iloc[0])\n","\n","        dist = float(np.sqrt((cx_det - cx_gt) ** 2 + (cy_det - cy_gt) ** 2))\n","        distances.append((label, dist))\n","\n","        # IoU (GTëŠ” ì›->bbox ê·¼ì‚¬)\n","        radius = get_template_radius(scene_id, template_dir, label)\n","        gt_bbox = (cx_gt - radius, cy_gt - radius, 2 * radius, 2 * radius)\n","        det_box = (int(x_det), int(y_det), int(w_det), int(h_det))\n","        iou = float(calculate_iou(det_box, gt_bbox))\n","        ious.append((label, iou))\n","\n","    # ê²°ê³¼ DF\n","    dist_map = {k: v for k, v in distances}\n","    iou_map = {k: v for k, v in ious}\n","\n","    final_rows = []\n","    for det in detections:\n","        label = det['label']\n","        gt_entry = df_scene[df_scene['template'] == label]\n","        if gt_entry.empty:\n","            gt_px = \"N/A\"\n","        else:\n","            gt_px = f\"{int(gt_entry['x'].iloc[0])}, {int(gt_entry['y'].iloc[0])}\"\n","\n","        final_rows.append({\n","            'scene_id': scene_id,\n","            'template_name': label,\n","            'ground_truth_px': gt_px,\n","            'distance': f\"{dist_map.get(label, 'N/A'):.2f}\" if label in dist_map else \"N/A\",\n","            'iou': f\"{iou_map.get(label, 'N/A'):.4f}\" if label in iou_map else \"N/A\"\n","        })\n","\n","    results_df = pd.DataFrame(final_rows)\n","\n","    metrics_csv_path = os.path.join(scene_out_dir, f\"{scene_id}_detection_metrics.csv\")\n","    results_df.to_csv(metrics_csv_path, index=False)\n","    print(f\"âœ“ Detection metrics saved to: {metrics_csv_path}\")\n","\n","    # Combined ì‹œê°í™”\n","    combined_output_path = os.path.join(scene_out_dir, f\"{scene_id}_det_and_gt_combined.png\")\n","    visualize_combined_results(\n","        scene_path=scene_path,\n","        detections=detections,\n","        df_scene_gt=df_scene,\n","        output_path=combined_output_path,\n","        template_dir=template_dir,\n","        scene_id=scene_id,\n","        iou_threshold=iou_threshold\n","    )\n","\n","    # Accuracy (0.5R)\n","    correct, wrong = [], []\n","    for _, row in results_df.iterrows():\n","        name = row['template_name']\n","        dist_val = row['distance']\n","\n","        distance = float(dist_val) if dist_val != \"N/A\" else float('inf')\n","        radius = get_template_radius(scene_id, template_dir, name)\n","\n","        if distance <= (radius * 0.5):\n","            correct.append(name)\n","        else:\n","            wrong.append(name)\n","\n","    total = len(results_df)\n","    acc = (len(correct) / total) * 100 if total > 0 else 0.0\n","\n","    print(f\"[{scene_id}] Accuracy(<=0.5R): {acc:.2f}% | Matched: {len(correct)}/{total}\")\n","\n","    return {\n","        'scene_id': scene_id,\n","        'n_templates': len(template_paths),\n","        'accuracy': acc,\n","        'matched': ', '.join(correct) if correct else '',\n","        'unmatched': ', '.join(wrong) if wrong else '',\n","        'metrics_csv': metrics_csv_path,\n","        '_correct_cnt': len(correct),\n","        '_total_cnt': total\n","    }"],"metadata":{"id":"BFOyo59-nEqL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_df_scene_gt(scene_id: str, gt_dir: str, gt_cache: dict):\n","    prefix = scene_id[:2].lower()\n","    gt_csv_path = os.path.join(gt_dir, f\"{prefix}-ground-truth.csv\")\n","\n","    if prefix not in gt_cache:\n","        if not os.path.exists(gt_csv_path):\n","            print(f\"âš ï¸ GT CSV ì—†ìŒ: {gt_csv_path}\")\n","            gt_cache[prefix] = pd.DataFrame(columns=['scene','template','px'])\n","        else:\n","            gt_cache[prefix] = pd.read_csv(gt_csv_path)\n","\n","    df_all = gt_cache[prefix]\n","    if df_all.empty:\n","        return df_all.copy()\n","\n","    # CSVì˜ scene ì»¬ëŸ¼ê³¼ ë¹„êµ\n","    df_scene = df_all[df_all['scene'] == scene_id].copy()\n","    if df_scene.empty:\n","        return df_scene\n","\n","    # px \"378, 50\" -> x,y\n","    split_coords = df_scene['px'].astype(str).str.split(',', expand=True)\n","    df_scene['x'] = split_coords[0].str.strip().astype(int)\n","    df_scene['y'] = split_coords[1].str.strip().astype(int)\n","    return df_scene"],"metadata":{"id":"2AVuMk6qCgFC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run_all_scenes_batch(scenes_dir, template_dir, output_dir,\n","                         gt_dir=None, scale_range=(0.7, 1.0), scale_step=0.1,\n","                         iou_threshold=0.5):\n","\n","    scene_files = []\n","    scene_files = sorted(\n","        glob.glob(os.path.join(scenes_dir, '*.jpg')) +\n","        glob.glob(os.path.join(scenes_dir, '*.JPG')) +\n","        glob.glob(os.path.join(scenes_dir, '*.png')) +\n","        glob.glob(os.path.join(scenes_dir, '*.PNG')) +\n","        glob.glob(os.path.join(scenes_dir, '*.jpeg')) +\n","        glob.glob(os.path.join(scenes_dir, '*.JPEG'))\n","    )\n","\n","    scene_files = scene_files[:]\n","    print(\"âœ… Run:\", [os.path.basename(p) for p in scene_files])\n","\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # prefixë³„ GT csv ìºì‹œ\n","    gt_cache = {}\n","\n","    summary_rows = []\n","\n","    # ì „ì²´ ì •í™•ë„ ê³„ì‚°ìš© ëˆ„ì  ì¹´ìš´í„° (ë°°ì¹˜ ë‹¨ìœ„)\n","    total_correct = 0\n","    total_total = 0\n","\n","    for scene_path in scene_files:\n","        scene_id = os.path.splitext(os.path.basename(scene_path))[0]\n","        print(f\"\\n{'='*90}\\nğŸš€ Processing: {scene_id}\\n{'='*90}\")\n","\n","        # scene_id prefixì— ë§ëŠ” GT ë¡œë“œ\n","        df_scene_gt = None\n","        if gt_dir is not None:\n","            df_scene_gt = get_df_scene_gt(scene_id, gt_dir, gt_cache)\n","\n","        try:\n","            info = evaluate_one_scene(\n","                scene_path=scene_path,\n","                template_dir=template_dir,\n","                output_dir=output_dir,\n","                df_scene_gt=df_scene_gt,\n","                scale_range=scale_range,\n","                scale_step=scale_step,\n","                iou_threshold=iou_threshold\n","            )\n","\n","            if info is None:\n","                continue\n","\n","            # ë°°ì¹˜ ì „ì²´ ì •í™•ë„ìš© ëˆ„ì \n","            total_correct += info.get('_correct_cnt', 0)\n","            total_total   += info.get('_total_cnt', 0)\n","\n","            # summary row (total_accuracyëŠ” ë‚˜ì¤‘ì— í•œ ë²ˆì— ë„£ìŒ)\n","            summary_rows.append({\n","                'scene_id': info['scene_id'],\n","                'n_templates': info['n_templates'],\n","                'accuracy': info['accuracy'],\n","                'matched': info['matched'],\n","                'unmatched': info['unmatched'],\n","                'metrics_csv': info['metrics_csv'],\n","            })\n","\n","        except Exception as e:\n","            print(f\"âŒ [{scene_id}] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}\")\n","            summary_rows.append({\n","                'scene_id': scene_id,\n","                'n_templates': None,\n","                'accuracy': None,\n","                'matched': '',\n","                'unmatched': '',\n","                'metrics_csv': None,\n","            })\n","\n","    # ë°°ì¹˜ ì „ì²´ ì •í™•ë„ê³„ì‚°\n","    total_acc = (total_correct / total_total * 100) if total_total > 0 else None\n","\n","    summary_df = pd.DataFrame(summary_rows)\n","\n","    # ëª¨ë“  í–‰ì— ë™ì¼í•œ total_accuracy ë„£ê¸°\n","    summary_df['total_accuracy'] = total_acc\n","\n","    # ì»¬ëŸ¼ ìˆœì„œ ì •ë ¬\n","    summary_df = summary_df[['scene_id', 'n_templates', 'accuracy', 'matched', 'unmatched', 'total_accuracy', 'metrics_csv']]\n","\n","    summary_csv = os.path.join(output_dir, \"batch_summary.csv\")\n","    summary_df.to_csv(summary_csv, index=False)\n","    print(f\"\\nâœ… Batch summary saved: {summary_csv}\")\n","    print(f\"âœ… Total Accuracy (all scenes): {total_acc if total_acc is not None else 'N/A'}\")\n","\n","    return summary_df"],"metadata":{"id":"1Svmyvx2nFCj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Main"],"metadata":{"id":"0bUD3xrnRRK8"}},{"cell_type":"code","source":["RANGE = (0.7, 1.3)\n","STEP = 0.1\n","\n","summary_df = run_all_scenes_batch(\n","    scenes_dir=scenes_dir,\n","    template_dir=template_dir,\n","    output_dir=output_dir,\n","    gt_dir=gt_dir,\n","    scale_range=RANGE,\n","    scale_step=STEP,\n","    iou_threshold=0.5\n",")\n","\n","display(summary_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_y0k8BIFnGZY","outputId":"243fc438-bd98-43f1-ad00-84760a7aa7fa","executionInfo":{"status":"ok","timestamp":1765640925391,"user_tz":-540,"elapsed":1719652,"user":{"displayName":"â€ì´ì •ì—°(ì¸ê³µì§€ëŠ¥ëŒ€í•™ ì¸ê³µì§€ëŠ¥í•™ê³¼)","userId":"14307825210431520220"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Run: ['ce-14.JPG', 'ge-07.jpg']\n","\n","==========================================================================================\n","ğŸš€ Processing: ce-14\n","==========================================================================================\n","ğŸ¨ [Info] Color Scene detected (/content/drive/MyDrive/Colab Notebooks/Solving Hidden Picture Puzzle/test/ce-14.JPG). Using Original Color Matcher.\n","Finding All Objects using MULTI method\n","==========================================================================================\n","\n","\n","ğŸ” Searching for: leaf\n","\n","==========================================================================================\n","   Optimized GHT (Rotated Table + Coarse-to-Fine): leaf\n","   Scale: (0.7, 1.3) | Rot Step: 15Â°\n","\n","ìƒìœ„ ê²°ê³¼:\n","  1. Scale 0.80x | Angle 0Â°| Votes 4866295\n","  2. Scale 0.70x | Angle 0Â°| Votes 4866295\n","  3. Scale 0.90x | Angle 0Â°| Votes 4866295\n","   âœ“ Best score: 1.0000 at scale 0.80x, angle 0Â°\n","\n","ğŸ” Searching for: paper airplane\n","\n","==========================================================================================\n","   Optimized GHT (Rotated Table + Coarse-to-Fine): paper airplane\n","   Scale: (0.7, 1.3) | Rot Step: 15Â°\n","\n","ìƒìœ„ ê²°ê³¼:\n","  1. Scale 0.80x | Angle 0Â°| Votes 6733354\n","  2. Scale 0.70x | Angle 0Â°| Votes 6733354\n","  3. Scale 0.70x | Angle 90Â°| Votes 6733354\n","   âœ“ Best score: 1.0000 at scale 0.80x, angle 0Â°\n","\n","ğŸ” Searching for: bug\n","\n","==========================================================================================\n","   Optimized GHT (Rotated Table + Coarse-to-Fine): bug\n","   Scale: (0.7, 1.3) | Rot Step: 15Â°\n","\n","ìƒìœ„ ê²°ê³¼:\n","  1. Scale 0.80x | Angle 0Â°| Votes 4583507\n","  2. Scale 0.90x | Angle 0Â°| Votes 4583507\n","  3. Scale 0.70x | Angle 0Â°| Votes 4583507\n","   âœ“ Best score: 1.0000 at scale 0.80x, angle 0Â°\n","\n","ğŸ” Searching for: fried chicken\n","\n","==========================================================================================\n","   Optimized GHT (Rotated Table + Coarse-to-Fine): fried chicken\n","   Scale: (0.7, 1.3) | Rot Step: 15Â°\n","\n","ìƒìœ„ ê²°ê³¼:\n","  1. Scale 0.80x | Angle 0Â°| Votes 1747396\n","  2. Scale 0.70x | Angle 90Â°| Votes 1747396\n","  3. Scale 0.90x | Angle 0Â°| Votes 1747396\n","   âœ“ Best score: 1.0000 at scale 0.80x, angle 0Â°\n","\n","ğŸ” Searching for: sock\n","\n","==========================================================================================\n","   Optimized GHT (Rotated Table + Coarse-to-Fine): sock\n","   Scale: (0.7, 1.3) | Rot Step: 15Â°\n","\n","ìƒìœ„ ê²°ê³¼:\n","  1. Scale 0.80x | Angle 0Â°| Votes 6518132\n","  2. Scale 0.70x | Angle 45Â°| Votes 6518132\n","  3. Scale 0.70x | Angle 30Â°| Votes 6518132\n","   âœ“ Best score: 1.0000 at scale 0.80x, angle 0Â°\n","\n","ğŸ” Searching for: lamp\n","\n","==========================================================================================\n","   Optimized GHT (Rotated Table + Coarse-to-Fine): lamp\n","   Scale: (0.7, 1.3) | Rot Step: 15Â°\n","\n","ìƒìœ„ ê²°ê³¼:\n","  1. Scale 0.80x | Angle 0Â°| Votes 9522276\n","  2. Scale 0.70x | Angle 0Â°| Votes 9522276\n","  3. Scale 0.90x | Angle 0Â°| Votes 9522276\n","   âœ“ Best score: 1.0000 at scale 0.80x, angle 0Â°\n","\n","âœ“ Visualization saved: /content/drive/MyDrive/Colab Notebooks/Solving Hidden Picture Puzzle/result/ce-14/ce-14_all_objects_multi.png\n","âœ“ Detection metrics saved to: /content/drive/MyDrive/Colab Notebooks/Solving Hidden Picture Puzzle/result/ce-14/ce-14_detection_metrics.csv\n","âœ“ Visualization saved: /content/drive/MyDrive/Colab Notebooks/Solving Hidden Picture Puzzle/result/ce-14/ce-14_det_and_gt_combined.png\n","[ce-14] Accuracy(<=0.5R): 100.00% | Matched: 6/6\n","\n","==========================================================================================\n","ğŸš€ Processing: ge-07\n","==========================================================================================\n","[Check] 3-channel image but Low Saturation (Mean S=0.00). Treating as Grayscale.\n","ğŸ–¤ [Info] Grayscale Scene detected (/content/drive/MyDrive/Colab Notebooks/Solving Hidden Picture Puzzle/test/ge-07.jpg). Using Grayscale Matcher.\n","Finding All Objects using MULTI method\n","==========================================================================================\n","\n","\n","ğŸ” Searching for: icecream\n","   --> Best: Scale 1.1x | Angle 0Â° | Score 0.9353\n","   âœ“ Best score: 0.9353 at scale 1.10x, angle 0Â°\n","\n","ğŸ” Searching for: watch\n","   --> Best: Scale 1.0x | Angle 0Â° | Score 0.9527\n","   âœ“ Best score: 0.9527 at scale 1.00x, angle 0Â°\n","\n","ğŸ” Searching for: bird\n","   --> Best: Scale 1.0x | Angle 0Â° | Score 0.9542\n","   âœ“ Best score: 0.9542 at scale 1.00x, angle 0Â°\n","\n","ğŸ” Searching for: brush\n","   --> Best: Scale 1.0x | Angle 0Â° | Score 0.9489\n","   âœ“ Best score: 0.9489 at scale 1.00x, angle 0Â°\n","\n","ğŸ” Searching for: eggplant\n","   --> Best: Scale 1.0x | Angle 0Â° | Score 0.9574\n","   âœ“ Best score: 0.9574 at scale 1.00x, angle 0Â°\n","\n","âœ“ Visualization saved: /content/drive/MyDrive/Colab Notebooks/Solving Hidden Picture Puzzle/result/ge-07/ge-07_all_objects_multi.png\n","âœ“ Detection metrics saved to: /content/drive/MyDrive/Colab Notebooks/Solving Hidden Picture Puzzle/result/ge-07/ge-07_detection_metrics.csv\n","âœ“ Visualization saved: /content/drive/MyDrive/Colab Notebooks/Solving Hidden Picture Puzzle/result/ge-07/ge-07_det_and_gt_combined.png\n","[ge-07] Accuracy(<=0.5R): 100.00% | Matched: 5/5\n","\n","âœ… Batch summary saved: /content/drive/MyDrive/Colab Notebooks/Solving Hidden Picture Puzzle/result/batch_summary.csv\n","âœ… Total Accuracy (all scenes): 100.0\n"]},{"output_type":"display_data","data":{"text/plain":["  scene_id  n_templates  accuracy  \\\n","0    ce-14            6     100.0   \n","1    ge-07            5     100.0   \n","\n","                                             matched unmatched  \\\n","0  leaf, paper airplane, bug, fried chicken, sock...             \n","1             icecream, watch, bird, brush, eggplant             \n","\n","   total_accuracy                                        metrics_csv  \n","0           100.0  /content/drive/MyDrive/Colab Notebooks/Solving...  \n","1           100.0  /content/drive/MyDrive/Colab Notebooks/Solving...  "],"text/html":["\n","  <div id=\"df-d279e68b-0e02-451a-8774-5431058a9da6\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>scene_id</th>\n","      <th>n_templates</th>\n","      <th>accuracy</th>\n","      <th>matched</th>\n","      <th>unmatched</th>\n","      <th>total_accuracy</th>\n","      <th>metrics_csv</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ce-14</td>\n","      <td>6</td>\n","      <td>100.0</td>\n","      <td>leaf, paper airplane, bug, fried chicken, sock...</td>\n","      <td></td>\n","      <td>100.0</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/Solving...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ge-07</td>\n","      <td>5</td>\n","      <td>100.0</td>\n","      <td>icecream, watch, bird, brush, eggplant</td>\n","      <td></td>\n","      <td>100.0</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/Solving...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d279e68b-0e02-451a-8774-5431058a9da6')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d279e68b-0e02-451a-8774-5431058a9da6 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d279e68b-0e02-451a-8774-5431058a9da6');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-15d316c6-18fd-4d35-8944-d9552ee64851\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15d316c6-18fd-4d35-8944-d9552ee64851')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-15d316c6-18fd-4d35-8944-d9552ee64851 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_4c34c361-85b4-48fa-ba68-2f09e576ed43\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('summary_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_4c34c361-85b4-48fa-ba68-2f09e576ed43 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('summary_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"summary_df","summary":"{\n  \"name\": \"summary_df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"scene_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"ge-07\",\n          \"ce-14\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_templates\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 5,\n        \"max\": 6,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          5,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 100.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"matched\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"icecream, watch, bird, brush, eggplant\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unmatched\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 100.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metrics_csv\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"/content/drive/MyDrive/Colab Notebooks/Solving Hidden Picture Puzzle/result/ge-07/ge-07_detection_metrics.csv\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}